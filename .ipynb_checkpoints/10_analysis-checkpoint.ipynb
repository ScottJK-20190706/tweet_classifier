{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.core.internals.managers'; 'pandas.core.internals' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f0ac0cfe5a47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0meval_data_formatted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet ID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_data_formatted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#set tweet id type as string\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclass_results_local\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'results/preds_per_tweet_local.pickle'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#tweet by tweet classifications per model local\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclass_results_colab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'results/preds_per_tweet_colab.pickle'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#tweet by tweet classifications per model colab\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#class_results = class_results_local.append(class_results_colab)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmetrics_local\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'results/metrics_local.pickle'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#overall metrics per model local\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(path, compression)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                 return read_wrapper(\n\u001b[1;32m--> 108\u001b[1;33m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m     82\u001b[0m                             is_text=False)\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_f\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                 return read_wrapper(\n\u001b[1;32m--> 108\u001b[1;33m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fh, encoding, compat, is_verbose)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1048\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnpicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STACK_GLOBAL requires str\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1347\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSTACK_GLOBAL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_stack_global\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_class_locations_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1386\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_compat_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMPORT_MAPPING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_compat_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMPORT_MAPPING\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1388\u001b[1;33m         \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.core.internals.managers'; 'pandas.core.internals' is not a package"
     ]
    }
   ],
   "source": [
    "eval_data_formatted = pd.read_pickle('pickle_files/eval_data_formatted.pickle') #raw evaluation data for referencing\n",
    "eval_data_formatted['Tweet ID'] = eval_data_formatted['Tweet ID'].astype(str) #set tweet id type as string\n",
    "class_results_local = pd.read_pickle('results/preds_per_tweet_local.pickle') #tweet by tweet classifications per model local\n",
    "class_results_colab = pd.read_pickle('results/preds_per_tweet_colab.pickle') #tweet by tweet classifications per model colab\n",
    "#class_results = class_results_local.append(class_results_colab)\n",
    "metrics_local = pd.read_pickle('results/metrics_local.pickle') #overall metrics per model local\n",
    "metrics_colab = pd.read_pickle('results/metrics_colab.pickle') #overall metrics per model colab\n",
    "#metrics = metrics_local.append(metrics_colab)\n",
    "actual = pd.read_pickle('features/df_tweet_eval.pickle') #get the actual classifications per tweet\n",
    "actual_class = actual.loc[:,['tweet_id','class_column']] #get the actual classifications per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>auc_sc</th>\n",
       "      <th>bp</th>\n",
       "      <th>f_1</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>name</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>tf</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950049</td>\n",
       "      <td>0.900298</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>features/df_tweet_tfidf_train.pickle</td>\n",
       "      <td>814.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950049</td>\n",
       "      <td>0.900298</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>features/df_tweet_tf_train.pickle</td>\n",
       "      <td>814.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.947111</td>\n",
       "      <td>0.912702</td>\n",
       "      <td>C 1;penalty l2;random_state 42</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>features/df_tweet_train.pickle</td>\n",
       "      <td>804.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941234</td>\n",
       "      <td>0.896912</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.826316</td>\n",
       "      <td>features/df_tweetbio_tfidf_train.pickle</td>\n",
       "      <td>804.0</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941234</td>\n",
       "      <td>0.896912</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.826316</td>\n",
       "      <td>features/df_tweetbio_tf_train.pickle</td>\n",
       "      <td>804.0</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc    auc_sc                                 bp       f_1    fn  \\\n",
       "0  0.950049  0.900298  C 0.05;penalty l2;random_state 42  0.859504  34.0   \n",
       "1  0.950049  0.900298  C 0.05;penalty l2;random_state 42  0.859504  34.0   \n",
       "2  0.947111  0.912702     C 1;penalty l2;random_state 42  0.857895  27.0   \n",
       "3  0.941234  0.896912  C 0.05;penalty l2;random_state 42  0.839572  33.0   \n",
       "4  0.941234  0.896912  C 0.05;penalty l2;random_state 42  0.839572  33.0   \n",
       "\n",
       "     fp name         p         r                                       tf  \\\n",
       "0  17.0   lr  0.901734  0.821053     features/df_tweet_tfidf_train.pickle   \n",
       "1  17.0   lr  0.901734  0.821053        features/df_tweet_tf_train.pickle   \n",
       "2  27.0   lr  0.857895  0.857895           features/df_tweet_train.pickle   \n",
       "3  27.0   lr  0.853261  0.826316  features/df_tweetbio_tfidf_train.pickle   \n",
       "4  27.0   lr  0.853261  0.826316     features/df_tweetbio_tf_train.pickle   \n",
       "\n",
       "      tn     tp  \n",
       "0  814.0  156.0  \n",
       "1  814.0  156.0  \n",
       "2  804.0  163.0  \n",
       "3  804.0  157.0  \n",
       "4  804.0  157.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>pred</th>\n",
       "      <th>model</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>1155803872268562433</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>1156043195316355072</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>1155810017171443713</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1147481872915673089</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>1156105129617252355</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>1155962324986892290</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>1154655243067645952</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>1156630745789677569</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1148459677988139008</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>1154410700082745344</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>1155939903928012800</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1148277346820087808</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513</th>\n",
       "      <td>1156280204203110400</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1148973554219868160</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>843135477645524992</td>\n",
       "      <td>1</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>885621747785105408</td>\n",
       "      <td>1</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>1156130857867993090</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>1153661917824737280</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>885621720635363328</td>\n",
       "      <td>1</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>1154462912179687424</td>\n",
       "      <td>1</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1148953945521426432</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>843401354739699712</td>\n",
       "      <td>1</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1153067862275366912</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>1154022420950466560</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>1155814641035034624</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>1156348028963479552</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1154134531189956609</td>\n",
       "      <td>1</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>1156095594936639488</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>842487327129767936</td>\n",
       "      <td>1</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>1156540644078305280</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>features/df_tweet_tfidf_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>894617486561292289</td>\n",
       "      <td>1</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>1150795191269384192</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>1154338290960613377</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>1157682570479452160</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>1154419397957705732</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>1155251858971213824</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>1153977236913033216</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>1157199326533300224</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>1153696798059503616</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>1156226904132898822</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1149931693932974080</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>1156232668746584064</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>840677105738403841</td>\n",
       "      <td>1</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1148955983936446466</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>1154298484801118208</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1148859530459123712</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>1154782366805778434</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1153789091063848961</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>1151219477402521600</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>1154864081767194625</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>1149726243891208192</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>1156104230547144704</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1147290184381325312</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>1156389581882834944</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1148285067564867590</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>1149009176665960448</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>1153332411641618434</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>839806979413590016</td>\n",
       "      <td>1</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>1154539315940089856</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>1148979096560590849</td>\n",
       "      <td>0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>features/df_tweet_eval.pickle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41861 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id  pred     model                                 file\n",
       "2778  1155803872268562433     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "3172  1156043195316355072     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "2788  1155810017171443713     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "144   1147481872915673089     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "3243  1156105129617252355     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "3102  1155962324986892290     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "2312  1154655243067645952     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "3799  1156630745789677569     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "318   1148459677988139008     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "2119  1154410700082745344     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "3029  1155939903928012800     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "296   1148277346820087808     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "3513  1156280204203110400     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "424   1148973554219868160     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "4512   843135477645524992     1        lr  features/df_tweet_tfidf_eval.pickle\n",
       "4652   885621747785105408     1        lr  features/df_tweet_tfidf_eval.pickle\n",
       "3311  1156130857867993090     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "1466  1153661917824737280     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "4651   885621720635363328     1        lr  features/df_tweet_tfidf_eval.pickle\n",
       "2199  1154462912179687424     1        lr  features/df_tweet_tfidf_eval.pickle\n",
       "414   1148953945521426432     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "4551   843401354739699712     1        lr  features/df_tweet_tfidf_eval.pickle\n",
       "1298  1153067862275366912     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "1709  1154022420950466560     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "2797  1155814641035034624     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "3603  1156348028963479552     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "1784  1154134531189956609     1        lr  features/df_tweet_tfidf_eval.pickle\n",
       "3220  1156095594936639488     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "4479   842487327129767936     1        lr  features/df_tweet_tfidf_eval.pickle\n",
       "3742  1156540644078305280     0        lr  features/df_tweet_tfidf_eval.pickle\n",
       "...                   ...   ...       ...                                  ...\n",
       "4772   894617486561292289     1  ensemble        features/df_tweet_eval.pickle\n",
       "840   1150795191269384192     0  ensemble        features/df_tweet_eval.pickle\n",
       "1982  1154338290960613377     0  ensemble        features/df_tweet_eval.pickle\n",
       "4155  1157682570479452160     0  ensemble        features/df_tweet_eval.pickle\n",
       "2133  1154419397957705732     0  ensemble        features/df_tweet_eval.pickle\n",
       "2608  1155251858971213824     0  ensemble        features/df_tweet_eval.pickle\n",
       "1683  1153977236913033216     0  ensemble        features/df_tweet_eval.pickle\n",
       "4002  1157199326533300224     0  ensemble        features/df_tweet_eval.pickle\n",
       "1501  1153696798059503616     0  ensemble        features/df_tweet_eval.pickle\n",
       "3441  1156226904132898822     0  ensemble        features/df_tweet_eval.pickle\n",
       "543   1149931693932974080     0  ensemble        features/df_tweet_eval.pickle\n",
       "3455  1156232668746584064     0  ensemble        features/df_tweet_eval.pickle\n",
       "4406   840677105738403841     1  ensemble        features/df_tweet_eval.pickle\n",
       "417   1148955983936446466     0  ensemble        features/df_tweet_eval.pickle\n",
       "1876  1154298484801118208     0  ensemble        features/df_tweet_eval.pickle\n",
       "370   1148859530459123712     0  ensemble        features/df_tweet_eval.pickle\n",
       "2403  1154782366805778434     0  ensemble        features/df_tweet_eval.pickle\n",
       "1607  1153789091063848961     0  ensemble        features/df_tweet_eval.pickle\n",
       "980   1151219477402521600     0  ensemble        features/df_tweet_eval.pickle\n",
       "2458  1154864081767194625     0  ensemble        features/df_tweet_eval.pickle\n",
       "506   1149726243891208192     0  ensemble        features/df_tweet_eval.pickle\n",
       "3240  1156104230547144704     0  ensemble        features/df_tweet_eval.pickle\n",
       "109   1147290184381325312     0  ensemble        features/df_tweet_eval.pickle\n",
       "3622  1156389581882834944     0  ensemble        features/df_tweet_eval.pickle\n",
       "299   1148285067564867590     0  ensemble        features/df_tweet_eval.pickle\n",
       "446   1149009176665960448     0  ensemble        features/df_tweet_eval.pickle\n",
       "1330  1153332411641618434     0  ensemble        features/df_tweet_eval.pickle\n",
       "4365   839806979413590016     1  ensemble        features/df_tweet_eval.pickle\n",
       "2278  1154539315940089856     0  ensemble        features/df_tweet_eval.pickle\n",
       "426   1148979096560590849     0  ensemble        features/df_tweet_eval.pickle\n",
       "\n",
       "[41861 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_results['desc'] = class_results['model']+ ' model using '+class_results['file']\n",
    "class_results_pivot = class_results.pivot(index='tweet_id',columns='desc',values='pred').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts of positives and negatives per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = class_results_pivot.copy() #copy the detailed results\n",
    "model_counts = len(df_check.columns)-1 #count the total number of models in df_check\n",
    "df_check['count_positive'] = df_check.sum(axis=1) #create a column counting the number of positives\n",
    "df_check = pd.merge(df_check, actual_class, on='tweet_id') #merge the actual class for each tweet\n",
    "df_check = df_check.loc[:,['tweet_id','count_positive','class_column']]   #create dataframe with the actual class and the\n",
    "df_check['count_negative'] = model_counts - df_check['count_positive']    #counts of positive and negative predictions per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "t_id = [] #array to hold tweet ids\n",
    "tweet = [] #array to hold tweet texts\n",
    "desc = [] #classifier and feature combo\n",
    "count = [] #number of classifier/feature combos classifying correctly\n",
    "t = [] #the type of correct classification\n",
    "\n",
    "for n in range(0,5): #n is the number of classifier/feature combos that got the right classification\n",
    "    tweet_list = df_check[(df_check.count_negative==n)&(df_check.class_column==0)].tweet_id #negative class \n",
    "    if n==0:                                                                                #tweets with n negative \n",
    "        if (len(tweet_list)>0): #if there are tweets without correct classification         #correct classifiers\n",
    "            t_id = np.append(t_id,tweet_list) #append tweet ids\n",
    "            tweet = np.append(tweet,eval_data_formatted[eval_data_formatted['Tweet ID'].isin(tweet_list)].Tweet) #append tweet text\n",
    "            desc = np.append(desc,np.repeat('no models',len(tweet_list))) #append classifier and feature combo description\n",
    "            count = np.append(count,np.repeat(n,len(tweet_list))) #append number of classifier/feature combos classifying correctly\n",
    "            t = np.append(t,np.repeat('tn',len(tweet_list))) #append the type of correct classification\n",
    "    else:\n",
    "        for tw_id in tweet_list: #go through each tweet id\n",
    "            t_id = np.append(t_id,np.repeat(tw_id,n)) #append tweet id\n",
    "            tweet = np.append(tweet,np.repeat(eval_data_formatted[eval_data_formatted['Tweet ID']==tw_id].Tweet,n)) #tweet text\n",
    "            desc = np.append(desc,class_results[(class_results.pred==0)&(class_results.tweet_id==tw_id)].desc) #classifier/feature combo\n",
    "            count = np.append(count,np.repeat(n,n)) #append number of classifier/feature combos classifying correctly\n",
    "            t = np.append(t,np.repeat('tn',n)) #append the type of correct classification\n",
    "            \n",
    "            \n",
    "    tweet_list = df_check[(df_check.count_positive==n)&(df_check.class_column==1)].tweet_id #positive class\n",
    "    if n==0:                                                                                #tweets with n negative \n",
    "        if (len(tweet_list)>0): #if there are tweets without correct classification         #correct classifiers\n",
    "            t_id = np.append(t_id,tweet_list) #append tweet ids\n",
    "            tweet = np.append(tweet,eval_data_formatted[eval_data_formatted['Tweet ID'].isin(tweet_list)].Tweet) #append tweet text\n",
    "            desc = np.append(desc,np.repeat('no models',len(tweet_list))) #append classifier and feature combo description\n",
    "            count = np.append(count,np.repeat(n,len(tweet_list))) #append number of classifier/feature combos classifying correctly\n",
    "            t = np.append(t,np.repeat('tp',len(tweet_list))) #append the type of correct classification\n",
    "    else:\n",
    "        for tw_id in tweet_list: #go through each tweet id\n",
    "            t_id = np.append(t_id,np.repeat(tw_id,n)) #append tweet id\n",
    "            tweet = np.append(tweet,np.repeat(eval_data_formatted[eval_data_formatted['Tweet ID']==tw_id].Tweet,n)) #tweet text\n",
    "            desc = np.append(desc,class_results[(class_results.pred==1)&(class_results.tweet_id==tw_id)].desc) #classifier/feature combo\n",
    "            count = np.append(count,np.repeat(n,n)) #append number of classifier/feature combos classifying correctly\n",
    "            t = np.append(t,np.repeat('tp',n)) #append the type of correct classification            \n",
    "            \n",
    "            \n",
    "print(len(t_id))\n",
    "print(len(tweet))\n",
    "print(len(desc))\n",
    "print(len(count))\n",
    "print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>desc</th>\n",
       "      <th>t</th>\n",
       "      <th>t_id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>no models</td>\n",
       "      <td>tn</td>\n",
       "      <td>1153765869761302529</td>\n",
       "      <td>Nicola sturgeon has a face I would punch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>no models</td>\n",
       "      <td>tp</td>\n",
       "      <td>861994773934206976</td>\n",
       "      <td>If you had a gun and one bullet with Donald Trump to the left and Nicolas Sturgeon to the right, which one gets it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>lr model using features/df_tweet_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>839521881493553152</td>\n",
       "      <td>How to recognise a slut: \"check Nicola Sturgeon as example, that's exactly the behaviour of the slut next door trying to spli…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>lr model using features/df_tweetbio_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>843217597999038469</td>\n",
       "      <td>not sure - sturgeon appears to be going mad &amp; introducing Sharia banking. the SNP has been bought by paki…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>dt model using features/df_tweet_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>888118576573325312</td>\n",
       "      <td>This may be a blessing in disguise. I'm enjoying all this Sturgeon news in the mean time. The Scottish dwarf an…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>lr model using features/df_tweet_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>903023685237448707</td>\n",
       "      <td>Sturgeon has no interest in Scotland's children because she has no children of her own.  Her womb is as barren as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>dt model using features/df_tweet_tfidf_eval.pickle</td>\n",
       "      <td>tn</td>\n",
       "      <td>1154792142348410880</td>\n",
       "      <td>A just wish Nicola sturgeon would shut the fuck up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>dt model using features/df_tweet_tf_eval.pickle</td>\n",
       "      <td>tn</td>\n",
       "      <td>1154792142348410880</td>\n",
       "      <td>A just wish Nicola sturgeon would shut the fuck up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>dt model using features/df_tweetbio_tfidf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>895011275800969217</td>\n",
       "      <td>Scotland SNP first minister Nicola Sturgeon now using miscarriage story for votes, can she stoop no lower?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>dt model using features/df_tweetbio_tf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>895011275800969217</td>\n",
       "      <td>Scotland SNP first minister Nicola Sturgeon now using miscarriage story for votes, can she stoop no lower?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>dt model using features/df_tweet_tfidf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>896656916738453504</td>\n",
       "      <td>\"Make the lie big,\\nmake it simple,\\nkeep saying it,\\nand eventually they will believe it.\"\\nA̶d̶o̶l̶f̶ ̶H̶i̶t̶l̶e̶r̶\\nNicola Sturg…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>dt model using features/df_tweet_tf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>896656916738453504</td>\n",
       "      <td>\"Make the lie big,\\nmake it simple,\\nkeep saying it,\\nand eventually they will believe it.\"\\nA̶d̶o̶l̶f̶ ̶H̶i̶t̶l̶e̶r̶\\nNicola Sturg…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>dt model using features/df_tweet_tfidf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>910247211031781376</td>\n",
       "      <td>As Andrew Neil steps down from his Sunday Politics role, a reminder of the time he called Sturgeon a 'Tipsy Scotch Tart'. htt…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>dt model using features/df_tweet_tf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>910247211031781376</td>\n",
       "      <td>As Andrew Neil steps down from his Sunday Politics role, a reminder of the time he called Sturgeon a 'Tipsy Scotch Tart'. htt…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>dt model using features/df_tweet_tfidf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>886137229004943361</td>\n",
       "      <td>big enough to bury sturgeon in lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>dt model using features/df_tweet_tf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>886137229004943361</td>\n",
       "      <td>big enough to bury sturgeon in lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>svm model using features/df_tweet_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>886137229004943361</td>\n",
       "      <td>big enough to bury sturgeon in lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lr model using features/df_tweet_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>894618728435994625</td>\n",
       "      <td>Me &amp;amp;   reckon Sturgeon is a tranny so therefore mentally ill.Scotland is no more a country than Lanna is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lr model using features/df_tweetbio_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>894618728435994625</td>\n",
       "      <td>Me &amp;amp;   reckon Sturgeon is a tranny so therefore mentally ill.Scotland is no more a country than Lanna is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>svm model using features/df_tweet_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>894618728435994625</td>\n",
       "      <td>Me &amp;amp;   reckon Sturgeon is a tranny so therefore mentally ill.Scotland is no more a country than Lanna is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.0</td>\n",
       "      <td>lr model using features/df_tweetbio_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>839632199636893696</td>\n",
       "      <td>I know this may be harsh,but  has lied about so many things in the last 2 yrs should we believe her about the mi…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.0</td>\n",
       "      <td>dt model using features/df_tweet_tfidf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>839632199636893696</td>\n",
       "      <td>I know this may be harsh,but  has lied about so many things in the last 2 yrs should we believe her about the mi…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.0</td>\n",
       "      <td>dt model using features/df_tweet_tf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>839632199636893696</td>\n",
       "      <td>I know this may be harsh,but  has lied about so many things in the last 2 yrs should we believe her about the mi…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>dt model using features/df_tweetbio_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>839632199636893696</td>\n",
       "      <td>I know this may be harsh,but  has lied about so many things in the last 2 yrs should we believe her about the mi…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.0</td>\n",
       "      <td>dt model using features/df_tweet_tfidf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>842488032825675776</td>\n",
       "      <td>Nicola Sturgeon.The Queen has had your bed made up in the tower.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.0</td>\n",
       "      <td>dt model using features/df_tweet_tf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>842488032825675776</td>\n",
       "      <td>Nicola Sturgeon.The Queen has had your bed made up in the tower.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.0</td>\n",
       "      <td>dt model using features/df_tweetbio_tfidf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>842488032825675776</td>\n",
       "      <td>Nicola Sturgeon.The Queen has had your bed made up in the tower.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.0</td>\n",
       "      <td>dt model using features/df_tweetbio_tf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>842488032825675776</td>\n",
       "      <td>Nicola Sturgeon.The Queen has had your bed made up in the tower.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.0</td>\n",
       "      <td>lr model using features/df_tweetbio_tfidf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>888117813142933504</td>\n",
       "      <td>You missed something in your eloquent description of Sturgeon... \"lazy FAT HUGE ENORMOUS mendacious arse\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.0</td>\n",
       "      <td>lr model using features/df_tweetbio_tf_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>888117813142933504</td>\n",
       "      <td>You missed something in your eloquent description of Sturgeon... \"lazy FAT HUGE ENORMOUS mendacious arse\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.0</td>\n",
       "      <td>lr model using features/df_tweetbio_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>888117813142933504</td>\n",
       "      <td>You missed something in your eloquent description of Sturgeon... \"lazy FAT HUGE ENORMOUS mendacious arse\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.0</td>\n",
       "      <td>dt model using features/df_tweet_eval.pickle</td>\n",
       "      <td>tp</td>\n",
       "      <td>888117813142933504</td>\n",
       "      <td>You missed something in your eloquent description of Sturgeon... \"lazy FAT HUGE ENORMOUS mendacious arse\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count                                                   desc   t  \\\n",
       "0     0.0                                              no models  tn   \n",
       "1     0.0                                              no models  tp   \n",
       "2     1.0           lr model using features/df_tweet_eval.pickle  tp   \n",
       "3     1.0        lr model using features/df_tweetbio_eval.pickle  tp   \n",
       "4     1.0           dt model using features/df_tweet_eval.pickle  tp   \n",
       "5     1.0           lr model using features/df_tweet_eval.pickle  tp   \n",
       "6     2.0     dt model using features/df_tweet_tfidf_eval.pickle  tn   \n",
       "7     2.0        dt model using features/df_tweet_tf_eval.pickle  tn   \n",
       "8     2.0  dt model using features/df_tweetbio_tfidf_eval.pickle  tp   \n",
       "9     2.0     dt model using features/df_tweetbio_tf_eval.pickle  tp   \n",
       "10    2.0     dt model using features/df_tweet_tfidf_eval.pickle  tp   \n",
       "11    2.0        dt model using features/df_tweet_tf_eval.pickle  tp   \n",
       "12    2.0     dt model using features/df_tweet_tfidf_eval.pickle  tp   \n",
       "13    2.0        dt model using features/df_tweet_tf_eval.pickle  tp   \n",
       "14    3.0     dt model using features/df_tweet_tfidf_eval.pickle  tp   \n",
       "15    3.0        dt model using features/df_tweet_tf_eval.pickle  tp   \n",
       "16    3.0          svm model using features/df_tweet_eval.pickle  tp   \n",
       "17    3.0           lr model using features/df_tweet_eval.pickle  tp   \n",
       "18    3.0        lr model using features/df_tweetbio_eval.pickle  tp   \n",
       "19    3.0          svm model using features/df_tweet_eval.pickle  tp   \n",
       "20    4.0        lr model using features/df_tweetbio_eval.pickle  tp   \n",
       "21    4.0     dt model using features/df_tweet_tfidf_eval.pickle  tp   \n",
       "22    4.0        dt model using features/df_tweet_tf_eval.pickle  tp   \n",
       "23    4.0        dt model using features/df_tweetbio_eval.pickle  tp   \n",
       "24    4.0     dt model using features/df_tweet_tfidf_eval.pickle  tp   \n",
       "25    4.0        dt model using features/df_tweet_tf_eval.pickle  tp   \n",
       "26    4.0  dt model using features/df_tweetbio_tfidf_eval.pickle  tp   \n",
       "27    4.0     dt model using features/df_tweetbio_tf_eval.pickle  tp   \n",
       "28    4.0  lr model using features/df_tweetbio_tfidf_eval.pickle  tp   \n",
       "29    4.0     lr model using features/df_tweetbio_tf_eval.pickle  tp   \n",
       "30    4.0        lr model using features/df_tweetbio_eval.pickle  tp   \n",
       "31    4.0           dt model using features/df_tweet_eval.pickle  tp   \n",
       "\n",
       "                   t_id  \\\n",
       "0   1153765869761302529   \n",
       "1    861994773934206976   \n",
       "2    839521881493553152   \n",
       "3    843217597999038469   \n",
       "4    888118576573325312   \n",
       "5    903023685237448707   \n",
       "6   1154792142348410880   \n",
       "7   1154792142348410880   \n",
       "8    895011275800969217   \n",
       "9    895011275800969217   \n",
       "10   896656916738453504   \n",
       "11   896656916738453504   \n",
       "12   910247211031781376   \n",
       "13   910247211031781376   \n",
       "14   886137229004943361   \n",
       "15   886137229004943361   \n",
       "16   886137229004943361   \n",
       "17   894618728435994625   \n",
       "18   894618728435994625   \n",
       "19   894618728435994625   \n",
       "20   839632199636893696   \n",
       "21   839632199636893696   \n",
       "22   839632199636893696   \n",
       "23   839632199636893696   \n",
       "24   842488032825675776   \n",
       "25   842488032825675776   \n",
       "26   842488032825675776   \n",
       "27   842488032825675776   \n",
       "28   888117813142933504   \n",
       "29   888117813142933504   \n",
       "30   888117813142933504   \n",
       "31   888117813142933504   \n",
       "\n",
       "                                                                                                                                   tweet  \n",
       "0                                                                                               Nicola sturgeon has a face I would punch  \n",
       "1                    If you had a gun and one bullet with Donald Trump to the left and Nicolas Sturgeon to the right, which one gets it?  \n",
       "2         How to recognise a slut: \"check Nicola Sturgeon as example, that's exactly the behaviour of the slut next door trying to spli…  \n",
       "3                             not sure - sturgeon appears to be going mad & introducing Sharia banking. the SNP has been bought by paki…  \n",
       "4                       This may be a blessing in disguise. I'm enjoying all this Sturgeon news in the mean time. The Scottish dwarf an…  \n",
       "5                   Sturgeon has no interest in Scotland's children because she has no children of her own.  Her womb is as barren as...  \n",
       "6                                                                                     A just wish Nicola sturgeon would shut the fuck up  \n",
       "7                                                                                     A just wish Nicola sturgeon would shut the fuck up  \n",
       "8                             Scotland SNP first minister Nicola Sturgeon now using miscarriage story for votes, can she stoop no lower?  \n",
       "9                             Scotland SNP first minister Nicola Sturgeon now using miscarriage story for votes, can she stoop no lower?  \n",
       "10  \"Make the lie big,\\nmake it simple,\\nkeep saying it,\\nand eventually they will believe it.\"\\nA̶d̶o̶l̶f̶ ̶H̶i̶t̶l̶e̶r̶\\nNicola Sturg…  \n",
       "11  \"Make the lie big,\\nmake it simple,\\nkeep saying it,\\nand eventually they will believe it.\"\\nA̶d̶o̶l̶f̶ ̶H̶i̶t̶l̶e̶r̶\\nNicola Sturg…  \n",
       "12        As Andrew Neil steps down from his Sunday Politics role, a reminder of the time he called Sturgeon a 'Tipsy Scotch Tart'. htt…  \n",
       "13        As Andrew Neil steps down from his Sunday Politics role, a reminder of the time he called Sturgeon a 'Tipsy Scotch Tart'. htt…  \n",
       "14                                                                                                    big enough to bury sturgeon in lol  \n",
       "15                                                                                                    big enough to bury sturgeon in lol  \n",
       "16                                                                                                    big enough to bury sturgeon in lol  \n",
       "17                         Me &amp;   reckon Sturgeon is a tranny so therefore mentally ill.Scotland is no more a country than Lanna is.  \n",
       "18                         Me &amp;   reckon Sturgeon is a tranny so therefore mentally ill.Scotland is no more a country than Lanna is.  \n",
       "19                         Me &amp;   reckon Sturgeon is a tranny so therefore mentally ill.Scotland is no more a country than Lanna is.  \n",
       "20                     I know this may be harsh,but  has lied about so many things in the last 2 yrs should we believe her about the mi…  \n",
       "21                     I know this may be harsh,but  has lied about so many things in the last 2 yrs should we believe her about the mi…  \n",
       "22                     I know this may be harsh,but  has lied about so many things in the last 2 yrs should we believe her about the mi…  \n",
       "23                     I know this may be harsh,but  has lied about so many things in the last 2 yrs should we believe her about the mi…  \n",
       "24                                                                      Nicola Sturgeon.The Queen has had your bed made up in the tower.  \n",
       "25                                                                      Nicola Sturgeon.The Queen has had your bed made up in the tower.  \n",
       "26                                                                      Nicola Sturgeon.The Queen has had your bed made up in the tower.  \n",
       "27                                                                      Nicola Sturgeon.The Queen has had your bed made up in the tower.  \n",
       "28                             You missed something in your eloquent description of Sturgeon... \"lazy FAT HUGE ENORMOUS mendacious arse\"  \n",
       "29                             You missed something in your eloquent description of Sturgeon... \"lazy FAT HUGE ENORMOUS mendacious arse\"  \n",
       "30                             You missed something in your eloquent description of Sturgeon... \"lazy FAT HUGE ENORMOUS mendacious arse\"  \n",
       "31                             You missed something in your eloquent description of Sturgeon... \"lazy FAT HUGE ENORMOUS mendacious arse\"  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Set the display.max_colwidth option to -1:\n",
    "\n",
    "pd.options.display.max_colwidth = 280\n",
    "df = pd.DataFrame({'t_id':t_id,'tweet':tweet,'desc':desc,'count':count,'t':t})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1146950933437399040\n",
       "2      1147011915782217729\n",
       "5      1147068052124721153\n",
       "7      1147105421477519360\n",
       "9      1147151158869291009\n",
       "10     1147183701471715334\n",
       "11     1147187636274159619\n",
       "12     1147203277680992257\n",
       "13     1147208820780949506\n",
       "15     1147213985332310016\n",
       "19     1147281943442145285\n",
       "20     1147290184381325312\n",
       "21     1147376927562297344\n",
       "22     1147391597946032128\n",
       "23     1147400639913353216\n",
       "24     1147425298465599488\n",
       "25     1147428283958661120\n",
       "26     1147436203521843200\n",
       "27     1147440752320032769\n",
       "28     1147443502516723714\n",
       "29     1147443835854905344\n",
       "30     1147476689351405571\n",
       "31     1147481872915673089\n",
       "32     1147496710706536455\n",
       "33     1147526639456333831\n",
       "34     1147557232885817345\n",
       "35     1147571451647733760\n",
       "36     1147593370614685697\n",
       "37     1147600128582279168\n",
       "38     1147601877841960960\n",
       "              ...         \n",
       "794    1157431335151132672\n",
       "795    1157459954317631488\n",
       "796    1157548075755458560\n",
       "797    1157574705827733504\n",
       "798    1157575328077877248\n",
       "799    1157581346560184320\n",
       "800    1157600016384561154\n",
       "804    1157679964965285888\n",
       "805    1157682570479452160\n",
       "806    1157690938375979008\n",
       "808    1157698496511795200\n",
       "809    1157731488496005120\n",
       "810    1157731626308263938\n",
       "812    1157751895525601280\n",
       "813    1157765828974194689\n",
       "814    1157775726105505792\n",
       "815    1157786826486222851\n",
       "817    1157811884684382216\n",
       "818    1157872039987830789\n",
       "819    1157872246909800449\n",
       "820    1157907761801416704\n",
       "822    1157941369828257792\n",
       "823    1157942918751105024\n",
       "824    1157970208595861504\n",
       "825    1157974240106352640\n",
       "826    1157974283911610368\n",
       "827    1157974330657169408\n",
       "828    1157974611818102784\n",
       "829    1157974810833686529\n",
       "830    1157974989318033415\n",
       "Name: tweet_id, Length: 628, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#negative class tweets where all classifiers were correct\n",
    "df_check[(df_check.count_negative==model_counts)&(df_check.class_column==0)].tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831     839518607986028546\n",
       "835     839518903969660928\n",
       "837     839519889475919873\n",
       "840     839520742316310534\n",
       "841     839520775027699713\n",
       "844     839521392160829440\n",
       "854     839772018002264064\n",
       "856     839779531166781440\n",
       "858     839806920273899521\n",
       "860     839806979413590016\n",
       "865     839902064465567744\n",
       "868     840250806536417284\n",
       "875     841450686340558848\n",
       "876     841452033232248833\n",
       "878     842335890127114241\n",
       "883     842483329576435712\n",
       "889     842785030787289089\n",
       "894     843135477645524992\n",
       "896     843202747327565824\n",
       "905     843402105633357824\n",
       "913     869579614493999106\n",
       "915     869583224577642496\n",
       "919     885612667490230272\n",
       "920     885613044558114818\n",
       "925     885621747785105408\n",
       "947     888673644951502849\n",
       "948     889528968084418561\n",
       "954     894616196473126912\n",
       "977     896854052042100736\n",
       "978     897362210825154560\n",
       "982     902242182064517120\n",
       "984     902243642894680065\n",
       "986     902473672618905600\n",
       "987     902473790403248128\n",
       "992     902479525300326400\n",
       "999     903361835130396672\n",
       "1006    906258064092876801\n",
       "1007    906258171336982529\n",
       "1008    906258533724942336\n",
       "1009    906258689958477835\n",
       "1010    906258763673456642\n",
       "1013    906431625009025024\n",
       "1014    910247040894013440\n",
       "Name: tweet_id, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive class tweets where all classifiers were correct\n",
    "df_check[(df_check.count_positive==model_counts)&(df_check.class_column==1)].tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
