{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\scott\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('pickle_files/train_data_formatted.pickle')\n",
    "eval_data = pd.read_pickle('pickle_files/eval_data_formatted.pickle')\n",
    "all_data = train_data.append(eval_data)\n",
    "all_data['Tweet ID'] = all_data['Tweet ID'].astype(str) #change the ID to str to avoid potential issues during aggregation\n",
    "all_data = all_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english') #get stopwords from NLTK\n",
    "keep = ['not'] #Waseem/Hovy did not use \"not\" as a stopword\n",
    "stop = [word for word in stop if word not in keep] #Waseem/Hovy did not use \"not\" as a stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Tweet_original'] = all_data.Tweet.copy() #keep a copy of the original tweet text\n",
    "all_data['Tweet'] = all_data['Tweet'].str.lower() #lowercase the text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation, usernames, hashtags, URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5104\n"
     ]
    }
   ],
   "source": [
    "all_data['Tweet'] = all_data['Tweet'].fillna('')\n",
    "p = re.compile(r'[^\\w\\s]+')\n",
    "all_data['Tweet'] = [p.sub('', x) for x in all_data['Tweet'].tolist()] #remove the punctuation\n",
    "for i in all_data.index:\n",
    "    #print(i)\n",
    "    #all_data.loc[i,'Tweet'] =re.sub('[^A-Za-z0-9]+',\"\",all_data.loc[i,'Tweet'])\n",
    "    all_data.loc[i,'Tweet'] =re.sub(\"@[A-Za-z0-9_/:().]+\",  \"\", all_data.loc[i,'Tweet'])\n",
    "    all_data.loc[i,'Tweet'] =re.sub(\"http[A-Za-z0-9_/:().]+\",  \"\", all_data.loc[i,'Tweet'])\n",
    "    all_data.loc[i,'Tweet'] =re.sub(\"#[A-Za-z0-9_/:().]+\",  \"\", all_data.loc[i,'Tweet'])\n",
    "print(len(np.unique(all_data['Tweet ID']))) #for convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5104\n"
     ]
    }
   ],
   "source": [
    "all_data['Tweet'] = all_data['Tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) #remove stopwords\n",
    "print(len(np.unique(all_data['Tweet ID']))) #for convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5104\n"
     ]
    }
   ],
   "source": [
    "all_data['Tweet'] = all_data['Tweet'].apply(word_tokenize) #tokenize the text\n",
    "print(len(np.unique(all_data['Tweet ID']))) #for convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tagged Gensim documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "tweet_docs = [TaggedDocument(doc, [i]) for i, doc in zip(all_data['Tweet ID'],all_data['Tweet'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "vec_size = 200\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=vec_size, min_count=2, epochs=100)\n",
    "model.build_vocab(tweet_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26min 43s\n"
     ]
    }
   ],
   "source": [
    "%time model.train(tweet_docs, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = [] #empty array to hold tweet ids\n",
    "tweet_vectors = [] #empty array to hold document vectors\n",
    "for t_id in all_data['Tweet ID']: #zip through tweets\n",
    "    vector = model.docvecs[t_id] #get vector for each tweet\n",
    "    tweet_ids.append(t_id)\n",
    "    tweet_vectors.append(vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "tweet_df = pd.DataFrame(data=tweet_vectors,\n",
    "          index=np.array(range(0, len(tweet_vectors))),\n",
    "          columns=np.array(range(0, vec_size)))\n",
    "feature_cols = tweet_df.columns\n",
    "tweet_df['tweet_id'] = tweet_ids\n",
    "tweet_df['class'] = all_data['class']\n",
    "tweet_df_train = tweet_df[tweet_df['tweet_id'].isin(train_data['Tweet ID'].astype(str))]\n",
    "tweet_df_eval = tweet_df[tweet_df['tweet_id'].isin(eval_data['Tweet ID'].astype(str))]\n",
    "\n",
    "x_train = scale(tweet_df_train[feature_cols])\n",
    "y_train = tweet_df_train['class']\n",
    "\n",
    "x_eval = scale(tweet_df_eval[feature_cols])\n",
    "y_eval = tweet_df_eval['class']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search, training, and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters\n",
      "{'C': 1, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.5977728951185969\n",
      "\n",
      "Evaluation data scores\n",
      "[[796  35]\n",
      " [ 83 107]]\n",
      "precision = 0.7535211267605634\n",
      "recall = 0.5631578947368421\n",
      "f1 = 0.6445783132530121\n",
      "auc = 0.7605199822661347\n",
      "accuracy = 0.8844270323212536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression #import lr\n",
    "from sklearn.svm import SVC #import svm\n",
    "from sklearn.tree import DecisionTreeClassifier #import dt\n",
    "from sklearn.ensemble import RandomForestClassifier #import rf\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, auc, roc_curve, accuracy_score #metrics\n",
    "from sklearn.model_selection import GridSearchCV #grid search\n",
    "log_clf = LogisticRegression()\n",
    "svc_clf = SVC()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "param_grid = [{'random_state':[42],\n",
    "       'C':[0.05,0.1,0.5,1],\n",
    "       'penalty':['l1','l2']}]\n",
    "\n",
    "classifier = log_clf\n",
    "\n",
    "param_grid = param_grid\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=10, scoring='recall') #grid search using 10-folds cross validation\n",
    "grid_search.fit(x_train, y_train) #fir grid search\n",
    "print(\"\")\n",
    "print('Best parameters')\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_parameters) #print best parameters from grid search\n",
    "print('Best grid search score = ',grid_search.best_score_) #print best grid search score\n",
    "print(\"\")\n",
    "print('Evaluation data scores')\n",
    "tuned_clf = grid_search.best_estimator_ #build model using best parameters\n",
    "tuned_clf_pred = tuned_clf.predict(x_eval) #predict using evaluation data with best parameters\n",
    "conf_matrix = confusion_matrix(y_eval,tuned_clf_pred) #build confusion matrix\n",
    "precision = precision_score(y_eval,tuned_clf_pred) #calculate precision\n",
    "recall = recall_score(y_eval,tuned_clf_pred) #calculate recall\n",
    "f1 = f1_score(y_eval,tuned_clf_pred) #calculate f1\n",
    "fpr, tpr, thresholds = roc_curve(y_eval,tuned_clf_pred)\n",
    "auc_score = auc(fpr, tpr) #calculate auc\n",
    "accuracy = accuracy_score(y_eval,tuned_clf_pred) #calculate accuracy\n",
    "#class_eval['pred'] = tuned_clf_pred\n",
    "#class_eval = class_eval.drop('class_column', axis=1) #join predictions onto actuals\n",
    "print(conf_matrix)\n",
    "print('precision = ' + str(precision))\n",
    "print('recall = ' + str(recall))\n",
    "print('f1 = ' + str(f1))\n",
    "print('auc = ' + str(auc_score))\n",
    "print('accuracy = ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataframes of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ';'.join('{} {}'.format(key, val) for key, val in best_parameters.items())\n",
    "\n",
    "tf = ['doc2vec']     #initialise empty vectors to hold results\n",
    "name = ['lr']\n",
    "bp = [b]\n",
    "tn = [conf_matrix[0][0]]\n",
    "fp = [conf_matrix[0][1]]\n",
    "fn = [conf_matrix[1][0]]\n",
    "tp = [conf_matrix[1][1]]\n",
    "p = [precision]\n",
    "r = [recall]\n",
    "f_1 = [f1]\n",
    "auc_sc = [auc_score]\n",
    "acc = [accuracy]\n",
    "\n",
    "classifications = pd.DataFrame({'tf':tf, #create a dataframe to hold the metrics\n",
    "                                'name':name,\n",
    "                               'bp':bp,\n",
    "                               'tn':tn,\n",
    "                               'fp':fp,\n",
    "                               'fn':fn,\n",
    "                               'tp':tp,\n",
    "                               'p':p,\n",
    "                               'r':r,\n",
    "                               'f_1':f_1,\n",
    "                               'auc_sc':auc_sc,\n",
    "                               'acc':acc})\n",
    "\n",
    "df_per_tweet = pd.DataFrame({'file':np.repeat('doc2vec',len(eval_data['Tweet ID'])),\n",
    "                             'model':np.repeat('lr',len(eval_data['Tweet ID'])),\n",
    "                             'pred': tuned_clf_pred,\n",
    "                             'tweet_id': eval_data['Tweet ID']\n",
    "                            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append results to existing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "metrics_local = pd.read_pickle('results/metrics_local.pickle')\n",
    "metrics_local = metrics_local.append(classifications)\n",
    "metrics_local.to_pickle('results/metrics_local.pickle') #pickle the metrics\n",
    "\n",
    "preds_per_tweet_local = pd.read_pickle('results/preds_per_tweet_local.pickle')\n",
    "preds_per_tweet_local = preds_per_tweet_local.append(df_per_tweet)\n",
    "preds_per_tweet_local.to_pickle('results/preds_per_tweet_local.pickle') #pickle the results of actual vs predicted for each tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
