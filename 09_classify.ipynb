{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data and class inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xysplit(file_location):\n",
    "    df = pd.read_pickle(file_location) #read file\n",
    "    df['tweet_id'] = df.tweet_id.astype(str) #change tweet_id to string\n",
    "    df = shuffle(df, random_state=42)\n",
    "    df_class = df.loc[:,['tweet_id','class_column']] #create a df of classes per tweet_id\n",
    "    x_df = df.drop(['tweet_id','class_column'], axis=1).values #drop tweet_id and class\n",
    "    x_df = scale(x_df) #scale the data\n",
    "    y_df = df_class.class_column.values #obtain a vector of classes\n",
    "    return(x_df,y_df, df_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classifiers and import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression #import lr\n",
    "from sklearn.svm import SVC #import svm\n",
    "from sklearn.tree import DecisionTreeClassifier #import dt\n",
    "from sklearn.ensemble import RandomForestClassifier #import rf\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, auc, roc_curve, accuracy_score #metrics\n",
    "from sklearn.model_selection import GridSearchCV #grid search\n",
    "log_clf = LogisticRegression()\n",
    "svc_clf = SVC()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for fine tuning and evaluating classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_grid(classifier,model, train_file, eval_file):\n",
    "    \n",
    "    if model == 'lr': #if using logisitic regression\n",
    "        param_grid = [{'random_state':[42],\n",
    "               'C':[0.05,0.1,0.5,1],\n",
    "               'penalty':['l1','l2']}]\n",
    "        \n",
    "    if model == 'dt': #if using decision tree\n",
    "        param_grid = [{'random_state':[42],\n",
    "                       'criterion':['gini','entropy']}]\n",
    "        \n",
    "    if model == 'rf': #if using random forest\n",
    "        param_grid = [{'random_state':[42],\n",
    "                       'criterion':['gini','entropy']}] \n",
    "    \n",
    "    if model == 'svm': #if using svm\n",
    "        param_grid = [{'random_state':[42],\n",
    "                   'C':[0.05,0.1,1,10], \n",
    "                   'kernel':['linear','rbf']}]\n",
    "    \n",
    "    x_train, y_train, class_train = xysplit(train_file) #split training data into X, Y\n",
    "    x_eval, y_eval, class_eval = xysplit(eval_file) #split evaluation data into X, Y\n",
    "    \n",
    "    param_grid = param_grid\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=10, scoring='recall') #grid search using 10-folds cross validation\n",
    "    grid_search.fit(x_train, y_train) #fir grid search\n",
    "    print(\"\")\n",
    "    print('Best parameters')\n",
    "    best_parameters = grid_search.best_params_\n",
    "    print(best_parameters) #print best parameters from grid search\n",
    "    print('Best grid search score = ',grid_search.best_score_) #print best grid search score\n",
    "    print(\"\")\n",
    "    print('Evaluation data scores')\n",
    "    tuned_clf = grid_search.best_estimator_ #build model using best parameters\n",
    "    tuned_clf_pred = tuned_clf.predict(x_eval) #predict using evaluation data with best parameters\n",
    "    conf_matrix = confusion_matrix(y_eval,tuned_clf_pred) #build confusion matrix\n",
    "    precision = precision_score(y_eval,tuned_clf_pred) #calculate precision\n",
    "    recall = recall_score(y_eval,tuned_clf_pred) #calculate recall\n",
    "    f1 = f1_score(y_eval,tuned_clf_pred) #calculate f1\n",
    "    fpr, tpr, thresholds = roc_curve(y_eval,tuned_clf_pred)\n",
    "    auc_score = auc(fpr, tpr) #calculate auc\n",
    "    accuracy = accuracy_score(y_eval,tuned_clf_pred) #calculate accuracy\n",
    "    class_eval['pred'] = tuned_clf_pred\n",
    "    class_eval = class_eval.drop('class_column', axis=1) #join predictions onto actuals\n",
    "    print(conf_matrix)\n",
    "    print('precision = ' + str(precision))\n",
    "    print('recall = ' + str(recall))\n",
    "    print('f1 = ' + str(f1))\n",
    "    print('auc = ' + str(auc_score))\n",
    "    print('accuracy = ' + str(accuracy))\n",
    "    \n",
    "    return(best_parameters, conf_matrix, precision, recall, f1, auc_score, accuracy, class_eval) #return metrics and pred vs actuals for each tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the \"search_grid()\" function for lr, dt, and rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters\n",
      "{'C': 0.1, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8320946725635374\n",
      "\n",
      "Evaluation data scores\n",
      "[[809  22]\n",
      " [ 31 159]]\n",
      "precision = 0.8784530386740331\n",
      "recall = 0.8368421052631579\n",
      "f1 = 0.8571428571428571\n",
      "auc = 0.9051839888529989\n",
      "accuracy = 0.9480901077375122\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.1, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8320946725635374\n",
      "\n",
      "Evaluation data scores\n",
      "[[809  22]\n",
      " [ 31 159]]\n",
      "precision = 0.8784530386740331\n",
      "recall = 0.8368421052631579\n",
      "f1 = 0.8571428571428571\n",
      "auc = 0.9051839888529989\n",
      "accuracy = 0.9480901077375122\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8428635265359182\n",
      "\n",
      "Evaluation data scores\n",
      "[[807  24]\n",
      " [ 27 163]]\n",
      "precision = 0.8716577540106952\n",
      "recall = 0.8578947368421053\n",
      "f1 = 0.8647214854111406\n",
      "auc = 0.9145069352080564\n",
      "accuracy = 0.9500489715964741\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8429128044989543\n",
      "\n",
      "Evaluation data scores\n",
      "[[801  30]\n",
      " [ 34 156]]\n",
      "precision = 0.8387096774193549\n",
      "recall = 0.8210526315789474\n",
      "f1 = 0.8297872340425532\n",
      "auc = 0.8924757742732282\n",
      "accuracy = 0.9373163565132223\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8429128044989543\n",
      "\n",
      "Evaluation data scores\n",
      "[[801  30]\n",
      " [ 34 156]]\n",
      "precision = 0.8387096774193549\n",
      "recall = 0.8210526315789474\n",
      "f1 = 0.8297872340425532\n",
      "auc = 0.8924757742732282\n",
      "accuracy = 0.9373163565132223\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8644782423368941\n",
      "\n",
      "Evaluation data scores\n",
      "[[794  37]\n",
      " [ 34 156]]\n",
      "precision = 0.8082901554404145\n",
      "recall = 0.8210526315789474\n",
      "f1 = 0.8146214099216709\n",
      "auc = 0.8882639812527708\n",
      "accuracy = 0.930460333006856\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8089994395146857\n",
      "\n",
      "Evaluation data scores\n",
      "[[805  26]\n",
      " [ 40 150]]\n",
      "precision = 0.8522727272727273\n",
      "recall = 0.7894736842105263\n",
      "f1 = 0.819672131147541\n",
      "auc = 0.8790930394578503\n",
      "accuracy = 0.9353574926542605\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8089994395146857\n",
      "\n",
      "Evaluation data scores\n",
      "[[805  26]\n",
      " [ 40 150]]\n",
      "precision = 0.8522727272727273\n",
      "recall = 0.7894736842105263\n",
      "f1 = 0.819672131147541\n",
      "auc = 0.8790930394578503\n",
      "accuracy = 0.9353574926542605\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8182271943706552\n",
      "\n",
      "Evaluation data scores\n",
      "[[805  26]\n",
      " [ 36 154]]\n",
      "precision = 0.8555555555555555\n",
      "recall = 0.8105263157894737\n",
      "f1 = 0.8324324324324324\n",
      "auc = 0.8896193552473239\n",
      "accuracy = 0.9392752203721841\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8151552403021911\n",
      "\n",
      "Evaluation data scores\n",
      "[[801  30]\n",
      " [ 35 155]]\n",
      "precision = 0.8378378378378378\n",
      "recall = 0.8157894736842105\n",
      "f1 = 0.8266666666666665\n",
      "auc = 0.8898441953258598\n",
      "accuracy = 0.9363369245837414\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8151552403021911\n",
      "\n",
      "Evaluation data scores\n",
      "[[801  30]\n",
      " [ 35 155]]\n",
      "precision = 0.8378378378378378\n",
      "recall = 0.8157894736842105\n",
      "f1 = 0.8266666666666665\n",
      "auc = 0.8898441953258598\n",
      "accuracy = 0.9363369245837414\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8444285875770078\n",
      "\n",
      "Evaluation data scores\n",
      "[[792  39]\n",
      " [ 40 150]]\n",
      "precision = 0.7936507936507936\n",
      "recall = 0.7894736842105263\n",
      "f1 = 0.7915567282321899\n",
      "auc = 0.871271138134144\n",
      "accuracy = 0.9226248775710089\n",
      "\n",
      "Best parameters\n",
      "{'C': 1, 'penalty': 'l1', 'random_state': 42}\n",
      "Best grid search score =  0.5285073899282202\n",
      "\n",
      "Evaluation data scores\n",
      "[[811  20]\n",
      " [ 89 101]]\n",
      "precision = 0.8347107438016529\n",
      "recall = 0.531578947368421\n",
      "f1 = 0.6495176848874599\n",
      "auc = 0.7537557793400469\n",
      "accuracy = 0.8932419196865817\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.7411161900186515\n",
      "\n",
      "Evaluation data scores\n",
      "[[786  45]\n",
      " [ 52 138]]\n",
      "precision = 0.7540983606557377\n",
      "recall = 0.7263157894736842\n",
      "f1 = 0.739946380697051\n",
      "auc = 0.836082082462474\n",
      "accuracy = 0.9049951028403526\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.7411161900186515\n",
      "\n",
      "Evaluation data scores\n",
      "[[786  45]\n",
      " [ 52 138]]\n",
      "precision = 0.7540983606557377\n",
      "recall = 0.7263157894736842\n",
      "f1 = 0.739946380697051\n",
      "auc = 0.836082082462474\n",
      "accuracy = 0.9049951028403526\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.7858740627178357\n",
      "\n",
      "Evaluation data scores\n",
      "[[798  33]\n",
      " [ 28 162]]\n",
      "precision = 0.8307692307692308\n",
      "recall = 0.8526315789473684\n",
      "f1 = 0.8415584415584415\n",
      "auc = 0.9064601938058141\n",
      "accuracy = 0.940254652301665\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.6733212522843308\n",
      "\n",
      "Evaluation data scores\n",
      "[[782  49]\n",
      " [ 63 127]]\n",
      "precision = 0.7215909090909091\n",
      "recall = 0.6684210526315789\n",
      "f1 = 0.6939890710382514\n",
      "auc = 0.8047279751725885\n",
      "accuracy = 0.8903036238981391\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.6733212522843308\n",
      "\n",
      "Evaluation data scores\n",
      "[[782  49]\n",
      " [ 63 127]]\n",
      "precision = 0.7215909090909091\n",
      "recall = 0.6684210526315789\n",
      "f1 = 0.6939890710382514\n",
      "auc = 0.8047279751725885\n",
      "accuracy = 0.8903036238981391\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.7180147751464799\n",
      "\n",
      "Evaluation data scores\n",
      "[[763  68]\n",
      " [ 59 131]]\n",
      "precision = 0.6582914572864321\n",
      "recall = 0.6894736842105263\n",
      "f1 = 0.6735218508997429\n",
      "auc = 0.8038222813351068\n",
      "accuracy = 0.8756121449559255\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.7257794984833927\n",
      "\n",
      "Evaluation data scores\n",
      "[[793  38]\n",
      " [ 56 134]]\n",
      "precision = 0.7790697674418605\n",
      "recall = 0.7052631578947368\n",
      "f1 = 0.7403314917127073\n",
      "auc = 0.8297675596934575\n",
      "accuracy = 0.9079333986287953\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.7257794984833927\n",
      "\n",
      "Evaluation data scores\n",
      "[[793  38]\n",
      " [ 56 134]]\n",
      "precision = 0.7790697674418605\n",
      "recall = 0.7052631578947368\n",
      "f1 = 0.7403314917127073\n",
      "auc = 0.8297675596934575\n",
      "accuracy = 0.9079333986287953\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.758183262212928\n",
      "\n",
      "Evaluation data scores\n",
      "[[782  49]\n",
      " [ 50 140]]\n",
      "precision = 0.7407407407407407\n",
      "recall = 0.7368421052631579\n",
      "f1 = 0.7387862796833774\n",
      "auc = 0.8389385014883779\n",
      "accuracy = 0.9030362389813908\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.617975211477232\n",
      "\n",
      "Evaluation data scores\n",
      "[[781  50]\n",
      " [ 70 120]]\n",
      "precision = 0.7058823529411765\n",
      "recall = 0.631578947368421\n",
      "f1 = 0.6666666666666667\n",
      "auc = 0.7857052378238014\n",
      "accuracy = 0.8824681684622919\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.617975211477232\n",
      "\n",
      "Evaluation data scores\n",
      "[[781  50]\n",
      " [ 70 120]]\n",
      "precision = 0.7058823529411765\n",
      "recall = 0.631578947368421\n",
      "f1 = 0.6666666666666667\n",
      "auc = 0.7857052378238014\n",
      "accuracy = 0.8824681684622919\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.6333923844646658\n",
      "\n",
      "Evaluation data scores\n",
      "[[777  54]\n",
      " [ 58 132]]\n",
      "precision = 0.7096774193548387\n",
      "recall = 0.6947368421052632\n",
      "f1 = 0.7021276595744681\n",
      "auc = 0.8148774463233897\n",
      "accuracy = 0.8903036238981391\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.6147629594566589\n",
      "\n",
      "Evaluation data scores\n",
      "[[735  96]\n",
      " [108  82]]\n",
      "precision = 0.4606741573033708\n",
      "recall = 0.43157894736842106\n",
      "f1 = 0.4456521739130435\n",
      "auc = 0.658027740832225\n",
      "accuracy = 0.8001958863858962\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.5793855032121931\n",
      "\n",
      "Evaluation data scores\n",
      "[[826   5]\n",
      " [ 70 120]]\n",
      "precision = 0.96\n",
      "recall = 0.631578947368421\n",
      "f1 = 0.7619047619047619\n",
      "auc = 0.8127810500981696\n",
      "accuracy = 0.9265426052889324\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.5793855032121931\n",
      "\n",
      "Evaluation data scores\n",
      "[[826   5]\n",
      " [ 70 120]]\n",
      "precision = 0.96\n",
      "recall = 0.631578947368421\n",
      "f1 = 0.7619047619047619\n",
      "auc = 0.8127810500981696\n",
      "accuracy = 0.9265426052889324\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.6056296981857232\n",
      "\n",
      "Evaluation data scores\n",
      "[[827   4]\n",
      " [ 73 117]]\n",
      "precision = 0.9669421487603306\n",
      "recall = 0.6157894736842106\n",
      "f1 = 0.752411575562701\n",
      "auc = 0.8054879979732724\n",
      "accuracy = 0.9245837414299706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.4345692270012623\n",
      "\n",
      "Evaluation data scores\n",
      "[[823   8]\n",
      " [104  86]]\n",
      "precision = 0.9148936170212766\n",
      "recall = 0.45263157894736844\n",
      "f1 = 0.6056338028169014\n",
      "auc = 0.7215023117360188\n",
      "accuracy = 0.8903036238981391\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.4345692270012623\n",
      "\n",
      "Evaluation data scores\n",
      "[[823   8]\n",
      " [104  86]]\n",
      "precision = 0.9148936170212766\n",
      "recall = 0.45263157894736844\n",
      "f1 = 0.6056338028169014\n",
      "auc = 0.7215023117360188\n",
      "accuracy = 0.8903036238981391\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.42223637172893236\n",
      "\n",
      "Evaluation data scores\n",
      "[[825   6]\n",
      " [104  86]]\n",
      "precision = 0.9347826086956522\n",
      "recall = 0.45263157894736844\n",
      "f1 = 0.6099290780141844\n",
      "auc = 0.7227056811704352\n",
      "accuracy = 0.8922624877571009\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.5686002232521337\n",
      "\n",
      "Evaluation data scores\n",
      "[[826   5]\n",
      " [ 78 112]]\n",
      "precision = 0.9572649572649573\n",
      "recall = 0.5894736842105263\n",
      "f1 = 0.7296416938110748\n",
      "auc = 0.7917284185192223\n",
      "accuracy = 0.9187071498530852\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.5686002232521337\n",
      "\n",
      "Evaluation data scores\n",
      "[[826   5]\n",
      " [ 78 112]]\n",
      "precision = 0.9572649572649573\n",
      "recall = 0.5894736842105263\n",
      "f1 = 0.7296416938110748\n",
      "auc = 0.7917284185192223\n",
      "accuracy = 0.9187071498530852\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.5685813834096347\n",
      "\n",
      "Evaluation data scores\n",
      "[[828   3]\n",
      " [ 78 112]]\n",
      "precision = 0.9739130434782609\n",
      "recall = 0.5894736842105263\n",
      "f1 = 0.7344262295081966\n",
      "auc = 0.7929317879536386\n",
      "accuracy = 0.920666013712047\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.41755626047966243\n",
      "\n",
      "Evaluation data scores\n",
      "[[823   8]\n",
      " [107  83]]\n",
      "precision = 0.9120879120879121\n",
      "recall = 0.4368421052631579\n",
      "f1 = 0.590747330960854\n",
      "auc = 0.7136075748939135\n",
      "accuracy = 0.8873653281096964\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.41755626047966243\n",
      "\n",
      "Evaluation data scores\n",
      "[[823   8]\n",
      " [107  83]]\n",
      "precision = 0.9120879120879121\n",
      "recall = 0.4368421052631579\n",
      "f1 = 0.590747330960854\n",
      "auc = 0.7136075748939135\n",
      "accuracy = 0.8873653281096964\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.4036987320785999\n",
      "\n",
      "Evaluation data scores\n",
      "[[824   7]\n",
      " [119  71]]\n",
      "precision = 0.9102564102564102\n",
      "recall = 0.3736842105263158\n",
      "f1 = 0.5298507462686568\n",
      "auc = 0.6826303122427007\n",
      "accuracy = 0.8765915768854065\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.5592475366905932\n",
      "\n",
      "Evaluation data scores\n",
      "[[814  17]\n",
      " [114  76]]\n",
      "precision = 0.8172043010752689\n",
      "recall = 0.4\n",
      "f1 = 0.5371024734982333\n",
      "auc = 0.6897713598074608\n",
      "accuracy = 0.871694417238002\n",
      "time taken =  0:47:45.930776\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "current = datetime.now() #for checking duration\n",
    "\n",
    "tf = []     #initialise empty vectors to hold results\n",
    "name = []\n",
    "bp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "tp = []\n",
    "p = []\n",
    "r = []\n",
    "f_1 = []\n",
    "auc_sc = []\n",
    "acc = []\n",
    "\n",
    "classifiers = [log_clf, dt_clf, rf_clf] #the classifiers that are to be tested\n",
    "models = ['lr','dt','rf'] #labels for identifying the results\n",
    "\n",
    "train_files = ['features/df_tweet_tfidf_train.pickle', #the file locations for the training data sets inc count features\n",
    "               'features/df_tweet_tf_train.pickle',\n",
    "               'features/df_tweet_train.pickle', \n",
    "               'features/df_tweetbio_tfidf_train.pickle',\n",
    "               'features/df_tweetbio_tf_train.pickle',\n",
    "               'features/df_tweetbio_train.pickle',\n",
    "               'features/df_tweet_tfidf_train_nc.pickle', #the file locations for the training data sets exc count features\n",
    "               'features/df_tweet_tf_train_nc.pickle',\n",
    "               'features/df_tweet_train_nc.pickle', \n",
    "               'features/df_tweetbio_tfidf_train_nc.pickle',\n",
    "               'features/df_tweetbio_tf_train_nc.pickle',\n",
    "               'features/df_tweetbio_train_nc.pickle',\n",
    "               'features/df_tweet_count_features_train.pickle'] #count features\n",
    "\n",
    "eval_files = ['features/df_tweet_tfidf_eval.pickle', #the file locations for the evaluation data sets inc count features\n",
    "              'features/df_tweet_tf_eval.pickle', \n",
    "              'features/df_tweet_eval.pickle', \n",
    "              'features/df_tweetbio_tfidf_eval.pickle', \n",
    "              'features/df_tweetbio_tf_eval.pickle',\n",
    "              'features/df_tweetbio_eval.pickle',\n",
    "              'features/df_tweet_tfidf_eval_nc.pickle', #the file locations for the evaluation data sets exc count features\n",
    "              'features/df_tweet_tf_eval_nc.pickle', \n",
    "              'features/df_tweet_eval_nc.pickle', \n",
    "              'features/df_tweetbio_tfidf_eval_nc.pickle', \n",
    "              'features/df_tweetbio_tf_eval_nc.pickle',\n",
    "              'features/df_tweetbio_eval_nc.pickle',\n",
    "              'features/df_tweet_count_features_eval.pickle'] #count features\n",
    "\n",
    "i=1 #a counter to be used for checking loop number\n",
    "for classifier, model in zip(classifiers, models): #zip through the classifiers and model names\n",
    "    for train_file, eval_file in zip(train_files, eval_files): #zip through the training and evaluation combos\n",
    "        #execute the search_grid() function\n",
    "        best_parameters, conf_matrix, precision, recall, f1, auc_score, accuracy, class_eval = search_grid(classifier,model, train_file, eval_file)\n",
    "        \n",
    "        #append the latest results to the vectors\n",
    "        tf = np.append(tf,train_file)\n",
    "        name = np.append(name,model)\n",
    "        b = ';'.join('{} {}'.format(key, val) for key, val in best_parameters.items())\n",
    "        bp = np.append(bp,b)\n",
    "        tn = np.append(tn,conf_matrix[0][0])\n",
    "        fp = np.append(fp,conf_matrix[0][1])\n",
    "        fn = np.append(fn,conf_matrix[1][0])\n",
    "        tp = np.append(tp,conf_matrix[1][1])\n",
    "        p = np.append(p,precision)\n",
    "        r = np.append(r,recall)\n",
    "        f_1 = np.append(f_1,f1)\n",
    "        auc_sc = np.append(auc_sc,auc_score)\n",
    "        acc = np.append(acc,accuracy)\n",
    "        \n",
    "        #col = train_file+'_'+model #build a column name\n",
    "        #class_eval.columns = ['tweet_id',col] #rename the columns\n",
    "        class_eval['model'] = model\n",
    "        class_eval['file'] = eval_file\n",
    "        if i==1: #if we are on the first iteration of the loop\n",
    "            df = class_eval.copy()\n",
    "        else: #if we are not on the first iteration f the loop\n",
    "            #df = pd.merge(df, class_eval, on='tweet_id')\n",
    "            df = df.append(class_eval)\n",
    "        \n",
    "        i = i+1 #increment i\n",
    "\n",
    "print('time taken = ',datetime.now() - current) #print the time taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the \"search_grid()\" function for svm (seperated process due to the long duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'kernel': 'linear', 'random_state': 42}\n",
      "Best grid search score =  0.8058580135270069\n",
      "\n",
      "Evaluation data scores\n",
      "[[803  28]\n",
      " [ 36 154]]\n",
      "precision = 0.8461538461538461\n",
      "recall = 0.8105263157894737\n",
      "f1 = 0.8279569892473119\n",
      "auc = 0.8884159858129077\n",
      "accuracy = 0.9373163565132223\n",
      "time taken =  0:17:49.487263\n"
     ]
    }
   ],
   "source": [
    "current = datetime.now()\n",
    "\n",
    "classifiers = [svc_clf] #the classifier that is to be tested\n",
    "models = ['svm'] #a lebale used to identify the results\n",
    "\n",
    "train_files = ['features/df_tweet_train.pickle'] #the location of the training data\n",
    "\n",
    "eval_files = ['features/df_tweet_eval.pickle'] #the location of the evaluation data\n",
    "\n",
    "for classifier, model in zip(classifiers, models): #zip through the classifier and label combos\n",
    "    for train_file, eval_file in zip(train_files, eval_files): #zip through the train and evaluation data combos\n",
    "        #execute the search_grid() function\n",
    "        best_parameters, conf_matrix, precision, recall, f1, auc_score, accuracy, class_eval = search_grid(classifier,model, train_file, eval_file)\n",
    "        \n",
    "        #append the latest results to the vectors\n",
    "        tf = np.append(tf,train_file)\n",
    "        name = np.append(name,model)\n",
    "        b = ';'.join('{} {}'.format(key, val) for key, val in best_parameters.items())\n",
    "        bp = np.append(bp,b)\n",
    "        tn = np.append(tn,conf_matrix[0][0])\n",
    "        fp = np.append(fp,conf_matrix[0][1])\n",
    "        fn = np.append(fn,conf_matrix[1][0])\n",
    "        tp = np.append(tp,conf_matrix[1][1])\n",
    "        p = np.append(p,precision)\n",
    "        r = np.append(r,recall)\n",
    "        f_1 = np.append(f_1,f1)\n",
    "        auc_sc = np.append(auc_sc,auc_score)\n",
    "        acc = np.append(acc,accuracy)\n",
    "        \n",
    "        class_eval['model'] = model\n",
    "        class_eval['file'] = eval_file\n",
    "\n",
    "        df = df.append(class_eval) #merge the latest predictions for each tweet using this classifier\n",
    "\n",
    "\n",
    "print('time taken = ',datetime.now() - current) #print the time taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the results so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf</th>\n",
       "      <th>name</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f_1</th>\n",
       "      <th>auc_sc</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>features/df_tweet_train.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.5;penalty l2;random_state 42</td>\n",
       "      <td>807.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.864721</td>\n",
       "      <td>0.914507</td>\n",
       "      <td>0.950049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>features/df_tweet_tfidf_train.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.1;penalty l2;random_state 42</td>\n",
       "      <td>809.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.878453</td>\n",
       "      <td>0.836842</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.905184</td>\n",
       "      <td>0.948090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>features/df_tweet_tf_train.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.1;penalty l2;random_state 42</td>\n",
       "      <td>809.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.878453</td>\n",
       "      <td>0.836842</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.905184</td>\n",
       "      <td>0.948090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>features/df_tweet_train.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>798.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.841558</td>\n",
       "      <td>0.906460</td>\n",
       "      <td>0.940255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>features/df_tweet_train_nc.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.5;penalty l2;random_state 42</td>\n",
       "      <td>805.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.832432</td>\n",
       "      <td>0.889619</td>\n",
       "      <td>0.939275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>features/df_tweetbio_tfidf_train.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>801.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.892476</td>\n",
       "      <td>0.937316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>features/df_tweetbio_tf_train.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>801.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.892476</td>\n",
       "      <td>0.937316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>features/df_tweet_train.pickle</td>\n",
       "      <td>svm</td>\n",
       "      <td>C 0.05;kernel linear;random_state 42</td>\n",
       "      <td>803.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.888416</td>\n",
       "      <td>0.937316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>features/df_tweetbio_tf_train_nc.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>801.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.889844</td>\n",
       "      <td>0.936337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>features/df_tweetbio_tfidf_train_nc.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>801.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.889844</td>\n",
       "      <td>0.936337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>features/df_tweet_tf_train_nc.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.5;penalty l2;random_state 42</td>\n",
       "      <td>805.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>0.935357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>features/df_tweet_tfidf_train_nc.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.5;penalty l2;random_state 42</td>\n",
       "      <td>805.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>0.935357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>features/df_tweetbio_train.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.5;penalty l2;random_state 42</td>\n",
       "      <td>794.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.808290</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.814621</td>\n",
       "      <td>0.888264</td>\n",
       "      <td>0.930460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>features/df_tweetbio_train_nc.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 0.5;penalty l2;random_state 42</td>\n",
       "      <td>792.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.791557</td>\n",
       "      <td>0.871271</td>\n",
       "      <td>0.922625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>features/df_tweet_tf_train.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>826.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.812781</td>\n",
       "      <td>0.926543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>features/df_tweet_tfidf_train.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>826.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.812781</td>\n",
       "      <td>0.926543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>features/df_tweet_train.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>827.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.615789</td>\n",
       "      <td>0.752412</td>\n",
       "      <td>0.805488</td>\n",
       "      <td>0.924584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>features/df_tweet_tfidf_train_nc.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>793.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.740331</td>\n",
       "      <td>0.829768</td>\n",
       "      <td>0.907933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>features/df_tweet_tf_train_nc.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>793.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.740331</td>\n",
       "      <td>0.829768</td>\n",
       "      <td>0.907933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>features/df_tweet_tf_train.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>786.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>0.739946</td>\n",
       "      <td>0.836082</td>\n",
       "      <td>0.904995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>features/df_tweet_tfidf_train.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>786.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>0.739946</td>\n",
       "      <td>0.836082</td>\n",
       "      <td>0.904995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>features/df_tweet_train_nc.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.738786</td>\n",
       "      <td>0.838939</td>\n",
       "      <td>0.903036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>features/df_tweet_train_nc.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>828.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>0.734426</td>\n",
       "      <td>0.792932</td>\n",
       "      <td>0.920666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>features/df_tweet_tf_train_nc.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>826.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>0.729642</td>\n",
       "      <td>0.791728</td>\n",
       "      <td>0.918707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>features/df_tweet_tfidf_train_nc.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>826.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>0.729642</td>\n",
       "      <td>0.791728</td>\n",
       "      <td>0.918707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>features/df_tweetbio_train_nc.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>777.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.814877</td>\n",
       "      <td>0.890304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>features/df_tweetbio_tf_train.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.721591</td>\n",
       "      <td>0.668421</td>\n",
       "      <td>0.693989</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.890304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>features/df_tweetbio_tfidf_train.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.721591</td>\n",
       "      <td>0.668421</td>\n",
       "      <td>0.693989</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.890304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>features/df_tweetbio_train.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>763.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.658291</td>\n",
       "      <td>0.689474</td>\n",
       "      <td>0.673522</td>\n",
       "      <td>0.803822</td>\n",
       "      <td>0.875612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>features/df_tweetbio_tf_train_nc.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>781.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.785705</td>\n",
       "      <td>0.882468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>features/df_tweetbio_tfidf_train_nc.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>781.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.785705</td>\n",
       "      <td>0.882468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>features/df_tweet_count_features_train.pickle</td>\n",
       "      <td>lr</td>\n",
       "      <td>C 1;penalty l1;random_state 42</td>\n",
       "      <td>811.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.753756</td>\n",
       "      <td>0.893242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>features/df_tweetbio_train.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>825.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.609929</td>\n",
       "      <td>0.722706</td>\n",
       "      <td>0.892262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>features/df_tweetbio_tf_train.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>823.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.721502</td>\n",
       "      <td>0.890304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>features/df_tweetbio_tfidf_train.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>823.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.721502</td>\n",
       "      <td>0.890304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>features/df_tweetbio_tfidf_train_nc.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>823.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.436842</td>\n",
       "      <td>0.590747</td>\n",
       "      <td>0.713608</td>\n",
       "      <td>0.887365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>features/df_tweetbio_tf_train_nc.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>823.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.436842</td>\n",
       "      <td>0.590747</td>\n",
       "      <td>0.713608</td>\n",
       "      <td>0.887365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>features/df_tweet_count_features_train.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>814.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.537102</td>\n",
       "      <td>0.689771</td>\n",
       "      <td>0.871694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>features/df_tweetbio_train_nc.pickle</td>\n",
       "      <td>rf</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>824.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>0.682630</td>\n",
       "      <td>0.876592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>features/df_tweet_count_features_train.pickle</td>\n",
       "      <td>dt</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>735.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.460674</td>\n",
       "      <td>0.431579</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.658028</td>\n",
       "      <td>0.800196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tf name  \\\n",
       "2                  features/df_tweet_train.pickle   lr   \n",
       "0            features/df_tweet_tfidf_train.pickle   lr   \n",
       "1               features/df_tweet_tf_train.pickle   lr   \n",
       "15                 features/df_tweet_train.pickle   dt   \n",
       "8               features/df_tweet_train_nc.pickle   lr   \n",
       "3         features/df_tweetbio_tfidf_train.pickle   lr   \n",
       "4            features/df_tweetbio_tf_train.pickle   lr   \n",
       "39                 features/df_tweet_train.pickle  svm   \n",
       "10        features/df_tweetbio_tf_train_nc.pickle   lr   \n",
       "9      features/df_tweetbio_tfidf_train_nc.pickle   lr   \n",
       "7            features/df_tweet_tf_train_nc.pickle   lr   \n",
       "6         features/df_tweet_tfidf_train_nc.pickle   lr   \n",
       "5               features/df_tweetbio_train.pickle   lr   \n",
       "11           features/df_tweetbio_train_nc.pickle   lr   \n",
       "27              features/df_tweet_tf_train.pickle   rf   \n",
       "26           features/df_tweet_tfidf_train.pickle   rf   \n",
       "28                 features/df_tweet_train.pickle   rf   \n",
       "19        features/df_tweet_tfidf_train_nc.pickle   dt   \n",
       "20           features/df_tweet_tf_train_nc.pickle   dt   \n",
       "14              features/df_tweet_tf_train.pickle   dt   \n",
       "13           features/df_tweet_tfidf_train.pickle   dt   \n",
       "21              features/df_tweet_train_nc.pickle   dt   \n",
       "34              features/df_tweet_train_nc.pickle   rf   \n",
       "33           features/df_tweet_tf_train_nc.pickle   rf   \n",
       "32        features/df_tweet_tfidf_train_nc.pickle   rf   \n",
       "24           features/df_tweetbio_train_nc.pickle   dt   \n",
       "17           features/df_tweetbio_tf_train.pickle   dt   \n",
       "16        features/df_tweetbio_tfidf_train.pickle   dt   \n",
       "18              features/df_tweetbio_train.pickle   dt   \n",
       "23        features/df_tweetbio_tf_train_nc.pickle   dt   \n",
       "22     features/df_tweetbio_tfidf_train_nc.pickle   dt   \n",
       "12  features/df_tweet_count_features_train.pickle   lr   \n",
       "31              features/df_tweetbio_train.pickle   rf   \n",
       "30           features/df_tweetbio_tf_train.pickle   rf   \n",
       "29        features/df_tweetbio_tfidf_train.pickle   rf   \n",
       "35     features/df_tweetbio_tfidf_train_nc.pickle   rf   \n",
       "36        features/df_tweetbio_tf_train_nc.pickle   rf   \n",
       "38  features/df_tweet_count_features_train.pickle   rf   \n",
       "37           features/df_tweetbio_train_nc.pickle   rf   \n",
       "25  features/df_tweet_count_features_train.pickle   dt   \n",
       "\n",
       "                                      bp     tn    fp     fn     tp         p  \\\n",
       "2       C 0.5;penalty l2;random_state 42  807.0  24.0   27.0  163.0  0.871658   \n",
       "0       C 0.1;penalty l2;random_state 42  809.0  22.0   31.0  159.0  0.878453   \n",
       "1       C 0.1;penalty l2;random_state 42  809.0  22.0   31.0  159.0  0.878453   \n",
       "15        criterion gini;random_state 42  798.0  33.0   28.0  162.0  0.830769   \n",
       "8       C 0.5;penalty l2;random_state 42  805.0  26.0   36.0  154.0  0.855556   \n",
       "3      C 0.05;penalty l2;random_state 42  801.0  30.0   34.0  156.0  0.838710   \n",
       "4      C 0.05;penalty l2;random_state 42  801.0  30.0   34.0  156.0  0.838710   \n",
       "39  C 0.05;kernel linear;random_state 42  803.0  28.0   36.0  154.0  0.846154   \n",
       "10     C 0.05;penalty l2;random_state 42  801.0  30.0   35.0  155.0  0.837838   \n",
       "9      C 0.05;penalty l2;random_state 42  801.0  30.0   35.0  155.0  0.837838   \n",
       "7       C 0.5;penalty l2;random_state 42  805.0  26.0   40.0  150.0  0.852273   \n",
       "6       C 0.5;penalty l2;random_state 42  805.0  26.0   40.0  150.0  0.852273   \n",
       "5       C 0.5;penalty l2;random_state 42  794.0  37.0   34.0  156.0  0.808290   \n",
       "11      C 0.5;penalty l2;random_state 42  792.0  39.0   40.0  150.0  0.793651   \n",
       "27        criterion gini;random_state 42  826.0   5.0   70.0  120.0  0.960000   \n",
       "26        criterion gini;random_state 42  826.0   5.0   70.0  120.0  0.960000   \n",
       "28        criterion gini;random_state 42  827.0   4.0   73.0  117.0  0.966942   \n",
       "19        criterion gini;random_state 42  793.0  38.0   56.0  134.0  0.779070   \n",
       "20        criterion gini;random_state 42  793.0  38.0   56.0  134.0  0.779070   \n",
       "14     criterion entropy;random_state 42  786.0  45.0   52.0  138.0  0.754098   \n",
       "13     criterion entropy;random_state 42  786.0  45.0   52.0  138.0  0.754098   \n",
       "21     criterion entropy;random_state 42  782.0  49.0   50.0  140.0  0.740741   \n",
       "34        criterion gini;random_state 42  828.0   3.0   78.0  112.0  0.973913   \n",
       "33        criterion gini;random_state 42  826.0   5.0   78.0  112.0  0.957265   \n",
       "32        criterion gini;random_state 42  826.0   5.0   78.0  112.0  0.957265   \n",
       "24     criterion entropy;random_state 42  777.0  54.0   58.0  132.0  0.709677   \n",
       "17     criterion entropy;random_state 42  782.0  49.0   63.0  127.0  0.721591   \n",
       "16     criterion entropy;random_state 42  782.0  49.0   63.0  127.0  0.721591   \n",
       "18        criterion gini;random_state 42  763.0  68.0   59.0  131.0  0.658291   \n",
       "23        criterion gini;random_state 42  781.0  50.0   70.0  120.0  0.705882   \n",
       "22        criterion gini;random_state 42  781.0  50.0   70.0  120.0  0.705882   \n",
       "12        C 1;penalty l1;random_state 42  811.0  20.0   89.0  101.0  0.834711   \n",
       "31     criterion entropy;random_state 42  825.0   6.0  104.0   86.0  0.934783   \n",
       "30        criterion gini;random_state 42  823.0   8.0  104.0   86.0  0.914894   \n",
       "29        criterion gini;random_state 42  823.0   8.0  104.0   86.0  0.914894   \n",
       "35        criterion gini;random_state 42  823.0   8.0  107.0   83.0  0.912088   \n",
       "36        criterion gini;random_state 42  823.0   8.0  107.0   83.0  0.912088   \n",
       "38     criterion entropy;random_state 42  814.0  17.0  114.0   76.0  0.817204   \n",
       "37     criterion entropy;random_state 42  824.0   7.0  119.0   71.0  0.910256   \n",
       "25        criterion gini;random_state 42  735.0  96.0  108.0   82.0  0.460674   \n",
       "\n",
       "           r       f_1    auc_sc       acc  \n",
       "2   0.857895  0.864721  0.914507  0.950049  \n",
       "0   0.836842  0.857143  0.905184  0.948090  \n",
       "1   0.836842  0.857143  0.905184  0.948090  \n",
       "15  0.852632  0.841558  0.906460  0.940255  \n",
       "8   0.810526  0.832432  0.889619  0.939275  \n",
       "3   0.821053  0.829787  0.892476  0.937316  \n",
       "4   0.821053  0.829787  0.892476  0.937316  \n",
       "39  0.810526  0.827957  0.888416  0.937316  \n",
       "10  0.815789  0.826667  0.889844  0.936337  \n",
       "9   0.815789  0.826667  0.889844  0.936337  \n",
       "7   0.789474  0.819672  0.879093  0.935357  \n",
       "6   0.789474  0.819672  0.879093  0.935357  \n",
       "5   0.821053  0.814621  0.888264  0.930460  \n",
       "11  0.789474  0.791557  0.871271  0.922625  \n",
       "27  0.631579  0.761905  0.812781  0.926543  \n",
       "26  0.631579  0.761905  0.812781  0.926543  \n",
       "28  0.615789  0.752412  0.805488  0.924584  \n",
       "19  0.705263  0.740331  0.829768  0.907933  \n",
       "20  0.705263  0.740331  0.829768  0.907933  \n",
       "14  0.726316  0.739946  0.836082  0.904995  \n",
       "13  0.726316  0.739946  0.836082  0.904995  \n",
       "21  0.736842  0.738786  0.838939  0.903036  \n",
       "34  0.589474  0.734426  0.792932  0.920666  \n",
       "33  0.589474  0.729642  0.791728  0.918707  \n",
       "32  0.589474  0.729642  0.791728  0.918707  \n",
       "24  0.694737  0.702128  0.814877  0.890304  \n",
       "17  0.668421  0.693989  0.804728  0.890304  \n",
       "16  0.668421  0.693989  0.804728  0.890304  \n",
       "18  0.689474  0.673522  0.803822  0.875612  \n",
       "23  0.631579  0.666667  0.785705  0.882468  \n",
       "22  0.631579  0.666667  0.785705  0.882468  \n",
       "12  0.531579  0.649518  0.753756  0.893242  \n",
       "31  0.452632  0.609929  0.722706  0.892262  \n",
       "30  0.452632  0.605634  0.721502  0.890304  \n",
       "29  0.452632  0.605634  0.721502  0.890304  \n",
       "35  0.436842  0.590747  0.713608  0.887365  \n",
       "36  0.436842  0.590747  0.713608  0.887365  \n",
       "38  0.400000  0.537102  0.689771  0.871694  \n",
       "37  0.373684  0.529851  0.682630  0.876592  \n",
       "25  0.431579  0.445652  0.658028  0.800196  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications = pd.DataFrame({'tf':tf, #create a dataframe to hold the metrics\n",
    "                                'name':name,\n",
    "                               'bp':bp,\n",
    "                               'tn':tn,\n",
    "                               'fp':fp,\n",
    "                               'fn':fn,\n",
    "                               'tp':tp,\n",
    "                               'p':p,\n",
    "                               'r':r,\n",
    "                               'f_1':f_1,\n",
    "                               'auc_sc':auc_sc,\n",
    "                               'acc':acc})\n",
    "\n",
    "classifications.sort_values(by='f_1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[821  10]\n",
      " [ 36 154]]\n",
      "precision = 0.9390243902439024\n",
      "recall = 0.8105263157894737\n",
      "f1 = 0.8700564971751412\n",
      "auc = 0.8992463107226549\n",
      "accuracy = 0.9549461312438785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "log_clf = LogisticRegression(penalty='l2',C=0.5, random_state=42) #logistic regression with best hyperparameters\n",
    "svc_clf = SVC(C=0.05, kernel='linear', probability = True, random_state=42) #svm with best hyperparameters\n",
    "dt_clf = DecisionTreeClassifier(criterion='gini', random_state=42) #random forest with best hyperparameters\n",
    "rf_clf = RandomForestClassifier(criterion='gini', random_state=42) #random forest with best hyperparameters\n",
    "\n",
    "#create the ensemble\n",
    "e_clf = VotingClassifier(estimators=[('lr', log_clf), ('svm', svc_clf), ('rf', rf_clf), ('dt', dt_clf)],\n",
    "                         voting='soft', weights=[1, 1, 1, 1])\n",
    "\n",
    "#get training and evaluation data\n",
    "x_train, y_train, class_train = xysplit('features/df_tweet_train.pickle') #split training data into X, Y\n",
    "x_eval, y_eval, class_eval = xysplit('features/df_tweet_eval.pickle') #split evaluation data into X, Y\n",
    "\n",
    "e_clf = e_clf.fit(x_train, y_train) #fit the ensemble\n",
    "\n",
    "e_clf_pred = e_clf.predict(x_eval) #predict using evaluation data with best parameters\n",
    "conf_matrix = confusion_matrix(y_eval,e_clf_pred) #build confusion matrix\n",
    "precision = precision_score(y_eval,e_clf_pred) #calculate precision\n",
    "recall = recall_score(y_eval,e_clf_pred) #calculate recall\n",
    "f1 = f1_score(y_eval,e_clf_pred) #calculate f1\n",
    "fpr, tpr, thresholds = roc_curve(y_eval,e_clf_pred)\n",
    "auc_score = auc(fpr, tpr) #calculate auc\n",
    "accuracy = accuracy_score(y_eval,e_clf_pred) #calculate accuracy\n",
    "class_eval['pred'] = e_clf_pred\n",
    "class_eval = class_eval.drop('class_column', axis=1) #join predictions onto actuals\n",
    "print(conf_matrix)\n",
    "print('precision = ' + str(precision))\n",
    "print('recall = ' + str(recall))\n",
    "print('f1 = ' + str(f1))\n",
    "print('auc = ' + str(auc_score))\n",
    "print('accuracy = ' + str(accuracy))\n",
    "\n",
    "#append the latest results to the vectors\n",
    "tf = np.append(tf,'features/df_tweet_train.pickle')\n",
    "name = np.append(name,'ensemble (lr,svc,dt,rf)')\n",
    "bp = np.append(bp,'ensemble')\n",
    "tn = np.append(tn,conf_matrix[0][0])\n",
    "fp = np.append(fp,conf_matrix[0][1])\n",
    "fn = np.append(fn,conf_matrix[1][0])\n",
    "tp = np.append(tp,conf_matrix[1][1])\n",
    "p = np.append(p,precision)\n",
    "r = np.append(r,recall)\n",
    "f_1 = np.append(f_1,f1)\n",
    "auc_sc = np.append(auc_sc,auc_score)\n",
    "acc = np.append(acc,accuracy)\n",
    "\n",
    "class_eval['model'] = 'ensemble (lr,svc,dt,rf)'\n",
    "class_eval['file'] = 'features/df_tweet_eval.pickle'\n",
    "\n",
    "df = df.append(class_eval) #merge the latest predictions for each tweet using this classifier\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('results/preds_per_tweet_local.pickle') #pickle the results of actual vs predicted for each tweet\n",
    "\n",
    "classifications = pd.DataFrame({'tf':tf, #create a dataframe to hold the metrics\n",
    "                                'name':name,\n",
    "                               'bp':bp,\n",
    "                               'tn':tn,\n",
    "                               'fp':fp,\n",
    "                               'fn':fn,\n",
    "                               'tp':tp,\n",
    "                               'p':p,\n",
    "                               'r':r,\n",
    "                               'f_1':f_1,\n",
    "                               'auc_sc':auc_sc,\n",
    "                               'acc':acc})\n",
    "classifications.to_pickle('results/metrics_local.pickle') #pickle the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print metric results descending by f1 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications.sort_values(by='f_1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
