{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data and class inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xysplit(file_location):\n",
    "    df = pd.read_pickle(file_location) #read file\n",
    "    df['tweet_id'] = df.tweet_id.astype(str) #change tweet_id to string\n",
    "    df = shuffle(df, random_state=42)\n",
    "    df_class = df.loc[:,['tweet_id','class_column']] #create a df of classes per tweet_id\n",
    "    x_df = df.drop(['tweet_id','class_column'], axis=1).values #drop tweet_id and class\n",
    "    x_df = scale(x_df) #scale the data\n",
    "    y_df = df_class.class_column.values #obtain a vector of classes\n",
    "    return(x_df,y_df, df_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classifiers and import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression #import lr\n",
    "from sklearn.svm import SVC #import svm\n",
    "from sklearn.tree import DecisionTreeClassifier #import dt\n",
    "from sklearn.ensemble import RandomForestClassifier #import rf\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, auc, roc_curve, accuracy_score #metrics\n",
    "from sklearn.model_selection import GridSearchCV #grid search\n",
    "log_clf = LogisticRegression()\n",
    "svc_clf = SVC()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for fine tuning and evaluating classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_grid(classifier,model, train_file, eval_file):\n",
    "    \n",
    "    if model == 'lr': #if using logisitic regression\n",
    "        param_grid = [{'random_state':[42],\n",
    "               'C':[0.05,0.1,0.5,1],\n",
    "               'penalty':['l1','l2']}]\n",
    "        \n",
    "    if model == 'dt': #if using decision tree\n",
    "        param_grid = [{'random_state':[42],\n",
    "                       'criterion':['gini','entropy']}]\n",
    "        \n",
    "    if model == 'rf': #if using random forest\n",
    "        param_grid = [{'random_state':[42],\n",
    "                       'criterion':['gini','entropy']}] \n",
    "    \n",
    "    if model == 'svm': #if using svm\n",
    "        param_grid = [{'random_state':[42],\n",
    "                   'C':[0.05,0.1,1,10], \n",
    "                   'kernel':['linear','rbf']}]\n",
    "    \n",
    "    x_train, y_train, class_train = xysplit(train_file) #split training data into X, Y\n",
    "    x_eval, y_eval, class_eval = xysplit(eval_file) #split evaluation data into X, Y\n",
    "    \n",
    "    param_grid = param_grid\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=10, scoring='recall') #grid search using 10-folds cross validation\n",
    "    grid_search.fit(x_train, y_train) #fir grid search\n",
    "    print(\"\")\n",
    "    print('Best parameters')\n",
    "    best_parameters = grid_search.best_params_\n",
    "    print(best_parameters) #print best parameters from grid search\n",
    "    print('Best grid search score = ',grid_search.best_score_) #print best grid search score\n",
    "    print(\"\")\n",
    "    print('Evaluation data scores')\n",
    "    tuned_clf = grid_search.best_estimator_ #build model using best parameters\n",
    "    tuned_clf_pred = tuned_clf.predict(x_eval) #predict using evaluation data with best parameters\n",
    "    conf_matrix = confusion_matrix(y_eval,tuned_clf_pred) #build confusion matrix\n",
    "    precision = precision_score(y_eval,tuned_clf_pred) #calculate precision\n",
    "    recall = recall_score(y_eval,tuned_clf_pred) #calculate recall\n",
    "    f1 = f1_score(y_eval,tuned_clf_pred) #calculate f1\n",
    "    fpr, tpr, thresholds = roc_curve(y_eval,tuned_clf_pred)\n",
    "    auc_score = auc(fpr, tpr) #calculate auc\n",
    "    accuracy = accuracy_score(y_eval,tuned_clf_pred) #calculate accuracy\n",
    "    class_eval['pred'] = tuned_clf_pred\n",
    "    class_eval = class_eval.drop('class_column', axis=1) #join predictions onto actuals\n",
    "    print(conf_matrix)\n",
    "    print('precision = ' + str(precision))\n",
    "    print('recall = ' + str(recall))\n",
    "    print('f1 = ' + str(f1))\n",
    "    print('auc = ' + str(auc_score))\n",
    "    print('accuracy = ' + str(accuracy))\n",
    "    \n",
    "    return(best_parameters, conf_matrix, precision, recall, f1, auc_score, accuracy, class_eval) #return metrics and pred vs actuals for each tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the \"search_grid()\" function for lr, dt, and rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.832074478607359\n",
      "\n",
      "Evaluation data scores\n",
      "[[814  17]\n",
      " [ 34 156]]\n",
      "precision = 0.9017341040462428\n",
      "recall = 0.8210526315789474\n",
      "f1 = 0.8595041322314049\n",
      "auc = 0.9002976755969345\n",
      "accuracy = 0.9500489715964741\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.832074478607359\n",
      "\n",
      "Evaluation data scores\n",
      "[[814  17]\n",
      " [ 34 156]]\n",
      "precision = 0.9017341040462428\n",
      "recall = 0.8210526315789474\n",
      "f1 = 0.8595041322314049\n",
      "auc = 0.9002976755969345\n",
      "accuracy = 0.9500489715964741\n",
      "\n",
      "Best parameters\n",
      "{'C': 1, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8413350854386856\n",
      "\n",
      "Evaluation data scores\n",
      "[[804  27]\n",
      " [ 27 163]]\n",
      "precision = 0.8578947368421053\n",
      "recall = 0.8578947368421053\n",
      "f1 = 0.8578947368421053\n",
      "auc = 0.9127018810564317\n",
      "accuracy = 0.9471106758080313\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8336535517813072\n",
      "\n",
      "Evaluation data scores\n",
      "[[804  27]\n",
      " [ 33 157]]\n",
      "precision = 0.8532608695652174\n",
      "recall = 0.8263157894736842\n",
      "f1 = 0.839572192513369\n",
      "auc = 0.8969124073722212\n",
      "accuracy = 0.941234084231146\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8336535517813072\n",
      "\n",
      "Evaluation data scores\n",
      "[[804  27]\n",
      " [ 33 157]]\n",
      "precision = 0.8532608695652174\n",
      "recall = 0.8263157894736842\n",
      "f1 = 0.839572192513369\n",
      "auc = 0.8969124073722212\n",
      "accuracy = 0.941234084231146\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.1, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.864465584317715\n",
      "\n",
      "Evaluation data scores\n",
      "[[797  34]\n",
      " [ 35 155]]\n",
      "precision = 0.8201058201058201\n",
      "recall = 0.8157894736842105\n",
      "f1 = 0.8179419525065964\n",
      "auc = 0.8874374564570271\n",
      "accuracy = 0.9324191968658179\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8089994395146857\n",
      "\n",
      "Evaluation data scores\n",
      "[[805  26]\n",
      " [ 40 150]]\n",
      "precision = 0.8522727272727273\n",
      "recall = 0.7894736842105263\n",
      "f1 = 0.819672131147541\n",
      "auc = 0.8790930394578503\n",
      "accuracy = 0.9353574926542605\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8089994395146857\n",
      "\n",
      "Evaluation data scores\n",
      "[[805  26]\n",
      " [ 40 150]]\n",
      "precision = 0.8522727272727273\n",
      "recall = 0.7894736842105263\n",
      "f1 = 0.819672131147541\n",
      "auc = 0.8790930394578503\n",
      "accuracy = 0.9353574926542605\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8182271943706552\n",
      "\n",
      "Evaluation data scores\n",
      "[[805  26]\n",
      " [ 36 154]]\n",
      "precision = 0.8555555555555555\n",
      "recall = 0.8105263157894737\n",
      "f1 = 0.8324324324324324\n",
      "auc = 0.8896193552473239\n",
      "accuracy = 0.9392752203721841\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8151552403021911\n",
      "\n",
      "Evaluation data scores\n",
      "[[801  30]\n",
      " [ 35 155]]\n",
      "precision = 0.8378378378378378\n",
      "recall = 0.8157894736842105\n",
      "f1 = 0.8266666666666665\n",
      "auc = 0.8898441953258598\n",
      "accuracy = 0.9363369245837414\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8151552403021911\n",
      "\n",
      "Evaluation data scores\n",
      "[[801  30]\n",
      " [ 35 155]]\n",
      "precision = 0.8378378378378378\n",
      "recall = 0.8157894736842105\n",
      "f1 = 0.8266666666666665\n",
      "auc = 0.8898441953258598\n",
      "accuracy = 0.9363369245837414\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42}\n",
      "Best grid search score =  0.8444285875770078\n",
      "\n",
      "Evaluation data scores\n",
      "[[792  39]\n",
      " [ 40 150]]\n",
      "precision = 0.7936507936507936\n",
      "recall = 0.7894736842105263\n",
      "f1 = 0.7915567282321899\n",
      "auc = 0.871271138134144\n",
      "accuracy = 0.9226248775710089\n",
      "\n",
      "Best parameters\n",
      "{'C': 0.5, 'penalty': 'l1', 'random_state': 42}\n",
      "Best grid search score =  0.5392156620320654\n",
      "\n",
      "Evaluation data scores\n",
      "[[804  27]\n",
      " [ 88 102]]\n",
      "precision = 0.7906976744186046\n",
      "recall = 0.5368421052631579\n",
      "f1 = 0.6394984326018809\n",
      "auc = 0.752175565266958\n",
      "accuracy = 0.8873653281096964\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.7396596346954539\n",
      "\n",
      "Evaluation data scores\n",
      "[[785  46]\n",
      " [ 52 138]]\n",
      "precision = 0.75\n",
      "recall = 0.7263157894736842\n",
      "f1 = 0.7379679144385027\n",
      "auc = 0.8354803977452657\n",
      "accuracy = 0.9040156709108716\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.7396596346954539\n",
      "\n",
      "Evaluation data scores\n",
      "[[785  46]\n",
      " [ 52 138]]\n",
      "precision = 0.75\n",
      "recall = 0.7263157894736842\n",
      "f1 = 0.7379679144385027\n",
      "auc = 0.8354803977452657\n",
      "accuracy = 0.9040156709108716\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.796716156577931\n",
      "\n",
      "Evaluation data scores\n",
      "[[794  37]\n",
      " [ 31 159]]\n",
      "precision = 0.8112244897959183\n",
      "recall = 0.8368421052631579\n",
      "f1 = 0.8238341968911916\n",
      "auc = 0.8961587180948762\n",
      "accuracy = 0.9333986287952988\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.6609571935228622\n",
      "\n",
      "Evaluation data scores\n",
      "[[779  52]\n",
      " [ 53 137]]\n",
      "precision = 0.7248677248677249\n",
      "recall = 0.7210526315789474\n",
      "f1 = 0.7229551451187335\n",
      "auc = 0.8292387104946483\n",
      "accuracy = 0.8971596474045054\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.6609571935228622\n",
      "\n",
      "Evaluation data scores\n",
      "[[779  52]\n",
      " [ 53 137]]\n",
      "precision = 0.7248677248677249\n",
      "recall = 0.7210526315789474\n",
      "f1 = 0.7229551451187335\n",
      "auc = 0.8292387104946483\n",
      "accuracy = 0.8971596474045054\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.7056178644096536\n",
      "\n",
      "Evaluation data scores\n",
      "[[737  94]\n",
      " [ 54 136]]\n",
      "precision = 0.591304347826087\n",
      "recall = 0.7157894736842105\n",
      "f1 = 0.6476190476190475\n",
      "auc = 0.8013363734245361\n",
      "accuracy = 0.8550440744368266\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.7257794984833927\n",
      "\n",
      "Evaluation data scores\n",
      "[[793  38]\n",
      " [ 56 134]]\n",
      "precision = 0.7790697674418605\n",
      "recall = 0.7052631578947368\n",
      "f1 = 0.7403314917127073\n",
      "auc = 0.8297675596934575\n",
      "accuracy = 0.9079333986287953\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.7257794984833927\n",
      "\n",
      "Evaluation data scores\n",
      "[[793  38]\n",
      " [ 56 134]]\n",
      "precision = 0.7790697674418605\n",
      "recall = 0.7052631578947368\n",
      "f1 = 0.7403314917127073\n",
      "auc = 0.8297675596934575\n",
      "accuracy = 0.9079333986287953\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.758183262212928\n",
      "\n",
      "Evaluation data scores\n",
      "[[782  49]\n",
      " [ 50 140]]\n",
      "precision = 0.7407407407407407\n",
      "recall = 0.7368421052631579\n",
      "f1 = 0.7387862796833774\n",
      "auc = 0.8389385014883779\n",
      "accuracy = 0.9030362389813908\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.617975211477232\n",
      "\n",
      "Evaluation data scores\n",
      "[[781  50]\n",
      " [ 70 120]]\n",
      "precision = 0.7058823529411765\n",
      "recall = 0.631578947368421\n",
      "f1 = 0.6666666666666667\n",
      "auc = 0.7857052378238014\n",
      "accuracy = 0.8824681684622919\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.617975211477232\n",
      "\n",
      "Evaluation data scores\n",
      "[[781  50]\n",
      " [ 70 120]]\n",
      "precision = 0.7058823529411765\n",
      "recall = 0.631578947368421\n",
      "f1 = 0.6666666666666667\n",
      "auc = 0.7857052378238014\n",
      "accuracy = 0.8824681684622919\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.6333923844646658\n",
      "\n",
      "Evaluation data scores\n",
      "[[777  54]\n",
      " [ 58 132]]\n",
      "precision = 0.7096774193548387\n",
      "recall = 0.6947368421052632\n",
      "f1 = 0.7021276595744681\n",
      "auc = 0.8148774463233897\n",
      "accuracy = 0.8903036238981391\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.5453752307880707\n",
      "\n",
      "Evaluation data scores\n",
      "[[685 146]\n",
      " [ 90 100]]\n",
      "precision = 0.4065040650406504\n",
      "recall = 0.5263157894736842\n",
      "f1 = 0.4587155963302752\n",
      "auc = 0.6753119260244473\n",
      "accuracy = 0.7688540646425074\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.6147729092484786\n",
      "\n",
      "Evaluation data scores\n",
      "[[828   3]\n",
      " [ 74 116]]\n",
      "precision = 0.9747899159663865\n",
      "recall = 0.6105263157894737\n",
      "f1 = 0.7508090614886731\n",
      "auc = 0.8034581037431123\n",
      "accuracy = 0.9245837414299706\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.6147729092484786\n",
      "\n",
      "Evaluation data scores\n",
      "[[828   3]\n",
      " [ 74 116]]\n",
      "precision = 0.9747899159663865\n",
      "recall = 0.6105263157894737\n",
      "f1 = 0.7508090614886731\n",
      "auc = 0.8034581037431123\n",
      "accuracy = 0.9245837414299706\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.622496184931894\n",
      "\n",
      "Evaluation data scores\n",
      "[[825   6]\n",
      " [ 73 117]]\n",
      "precision = 0.9512195121951219\n",
      "recall = 0.6157894736842106\n",
      "f1 = 0.7476038338658147\n",
      "auc = 0.8042846285388562\n",
      "accuracy = 0.9226248775710089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.46237606916106183\n",
      "\n",
      "Evaluation data scores\n",
      "[[826   5]\n",
      " [ 96  94]]\n",
      "precision = 0.9494949494949495\n",
      "recall = 0.49473684210526314\n",
      "f1 = 0.6505190311418685\n",
      "auc = 0.7443599974665907\n",
      "accuracy = 0.901077375122429\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.46237606916106183\n",
      "\n",
      "Evaluation data scores\n",
      "[[826   5]\n",
      " [ 96  94]]\n",
      "precision = 0.9494949494949495\n",
      "recall = 0.49473684210526314\n",
      "f1 = 0.6505190311418685\n",
      "auc = 0.7443599974665907\n",
      "accuracy = 0.901077375122429\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.43749605540797687\n",
      "\n",
      "Evaluation data scores\n",
      "[[826   5]\n",
      " [104  86]]\n",
      "precision = 0.945054945054945\n",
      "recall = 0.45263157894736844\n",
      "f1 = 0.6120996441281138\n",
      "auc = 0.7233073658876433\n",
      "accuracy = 0.8932419196865817\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.5686002232521337\n",
      "\n",
      "Evaluation data scores\n",
      "[[826   5]\n",
      " [ 78 112]]\n",
      "precision = 0.9572649572649573\n",
      "recall = 0.5894736842105263\n",
      "f1 = 0.7296416938110748\n",
      "auc = 0.7917284185192223\n",
      "accuracy = 0.9187071498530852\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.5686002232521337\n",
      "\n",
      "Evaluation data scores\n",
      "[[826   5]\n",
      " [ 78 112]]\n",
      "precision = 0.9572649572649573\n",
      "recall = 0.5894736842105263\n",
      "f1 = 0.7296416938110748\n",
      "auc = 0.7917284185192223\n",
      "accuracy = 0.9187071498530852\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.5685813834096347\n",
      "\n",
      "Evaluation data scores\n",
      "[[828   3]\n",
      " [ 78 112]]\n",
      "precision = 0.9739130434782609\n",
      "recall = 0.5894736842105263\n",
      "f1 = 0.7344262295081966\n",
      "auc = 0.7929317879536386\n",
      "accuracy = 0.920666013712047\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.41755626047966243\n",
      "\n",
      "Evaluation data scores\n",
      "[[823   8]\n",
      " [107  83]]\n",
      "precision = 0.9120879120879121\n",
      "recall = 0.4368421052631579\n",
      "f1 = 0.590747330960854\n",
      "auc = 0.7136075748939135\n",
      "accuracy = 0.8873653281096964\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.41755626047966243\n",
      "\n",
      "Evaluation data scores\n",
      "[[823   8]\n",
      " [107  83]]\n",
      "precision = 0.9120879120879121\n",
      "recall = 0.4368421052631579\n",
      "f1 = 0.590747330960854\n",
      "auc = 0.7136075748939135\n",
      "accuracy = 0.8873653281096964\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'entropy', 'random_state': 42}\n",
      "Best grid search score =  0.4036987320785999\n",
      "\n",
      "Evaluation data scores\n",
      "[[824   7]\n",
      " [119  71]]\n",
      "precision = 0.9102564102564102\n",
      "recall = 0.3736842105263158\n",
      "f1 = 0.5298507462686568\n",
      "auc = 0.6826303122427007\n",
      "accuracy = 0.8765915768854065\n",
      "\n",
      "Best parameters\n",
      "{'criterion': 'gini', 'random_state': 42}\n",
      "Best grid search score =  0.5438290095894798\n",
      "\n",
      "Evaluation data scores\n",
      "[[801  30]\n",
      " [122  68]]\n",
      "precision = 0.6938775510204082\n",
      "recall = 0.35789473684210527\n",
      "f1 = 0.47222222222222215\n",
      "auc = 0.6608968269048072\n",
      "accuracy = 0.8511263467189031\n",
      "time taken =  0:40:16.358571\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "current = datetime.now() #for checking duration\n",
    "\n",
    "tf = []     #initialise empty vectors to hold results\n",
    "name = []\n",
    "bp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "tp = []\n",
    "p = []\n",
    "r = []\n",
    "f_1 = []\n",
    "auc_sc = []\n",
    "acc = []\n",
    "\n",
    "classifiers = [log_clf, dt_clf, rf_clf] #the classifiers that are to be tested\n",
    "models = ['lr','dt','rf'] #labels for identifying the results\n",
    "\n",
    "train_files = ['features/df_tweet_tfidf_train.pickle', #the file locations for the training data sets inc count features\n",
    "               'features/df_tweet_tf_train.pickle',\n",
    "               'features/df_tweet_train.pickle', \n",
    "               'features/df_tweetbio_tfidf_train.pickle',\n",
    "               'features/df_tweetbio_tf_train.pickle',\n",
    "               'features/df_tweetbio_train.pickle',\n",
    "               'features/df_tweet_tfidf_train_nc.pickle', #the file locations for the training data sets exc count features\n",
    "               'features/df_tweet_tf_train_nc.pickle',\n",
    "               'features/df_tweet_train_nc.pickle', \n",
    "               'features/df_tweetbio_tfidf_train_nc.pickle',\n",
    "               'features/df_tweetbio_tf_train_nc.pickle',\n",
    "               'features/df_tweetbio_train_nc.pickle',\n",
    "               'features/df_tweet_count_features_train.pickle'] #count features\n",
    "\n",
    "eval_files = ['features/df_tweet_tfidf_eval.pickle', #the file locations for the evaluation data sets inc count features\n",
    "              'features/df_tweet_tf_eval.pickle', \n",
    "              'features/df_tweet_eval.pickle', \n",
    "              'features/df_tweetbio_tfidf_eval.pickle', \n",
    "              'features/df_tweetbio_tf_eval.pickle',\n",
    "              'features/df_tweetbio_eval.pickle',\n",
    "              'features/df_tweet_tfidf_eval_nc.pickle', #the file locations for the evaluation data sets exc count features\n",
    "              'features/df_tweet_tf_eval_nc.pickle', \n",
    "              'features/df_tweet_eval_nc.pickle', \n",
    "              'features/df_tweetbio_tfidf_eval_nc.pickle', \n",
    "              'features/df_tweetbio_tf_eval_nc.pickle',\n",
    "              'features/df_tweetbio_eval_nc.pickle',\n",
    "              'features/df_tweet_count_features_eval.pickle'] #count features\n",
    "\n",
    "i=1 #a counter to be used for checking loop number\n",
    "for classifier, model in zip(classifiers, models): #zip through the classifiers and model names\n",
    "    for train_file, eval_file in zip(train_files, eval_files): #zip through the training and evaluation combos\n",
    "        #execute the search_grid() function\n",
    "        best_parameters, conf_matrix, precision, recall, f1, auc_score, accuracy, class_eval = search_grid(classifier,model, train_file, eval_file)\n",
    "        \n",
    "        #append the latest results to the vectors\n",
    "        tf = np.append(tf,train_file)\n",
    "        name = np.append(name,model)\n",
    "        b = ';'.join('{} {}'.format(key, val) for key, val in best_parameters.items())\n",
    "        bp = np.append(bp,b)\n",
    "        tn = np.append(tn,conf_matrix[0][0])\n",
    "        fp = np.append(fp,conf_matrix[0][1])\n",
    "        fn = np.append(fn,conf_matrix[1][0])\n",
    "        tp = np.append(tp,conf_matrix[1][1])\n",
    "        p = np.append(p,precision)\n",
    "        r = np.append(r,recall)\n",
    "        f_1 = np.append(f_1,f1)\n",
    "        auc_sc = np.append(auc_sc,auc_score)\n",
    "        acc = np.append(acc,accuracy)\n",
    "        \n",
    "        #col = train_file+'_'+model #build a column name\n",
    "        #class_eval.columns = ['tweet_id',col] #rename the columns\n",
    "        class_eval['model'] = model\n",
    "        class_eval['file'] = eval_file\n",
    "        if i==1: #if we are on the first iteration of the loop\n",
    "            df = class_eval.copy()\n",
    "        else: #if we are not on the first iteration f the loop\n",
    "            #df = pd.merge(df, class_eval, on='tweet_id')\n",
    "            df = df.append(class_eval)\n",
    "        \n",
    "        i = i+1 #increment i\n",
    "\n",
    "print('time taken = ',datetime.now() - current) #print the time taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the \"search_grid()\" function for svm (seperated process due to the long duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters\n",
      "{'C': 0.05, 'kernel': 'linear', 'random_state': 42}\n",
      "Best grid search score =  0.8058744395146857\n",
      "\n",
      "Evaluation data scores\n",
      "[[802  29]\n",
      " [ 37 153]]\n",
      "precision = 0.8406593406593407\n",
      "recall = 0.8052631578947368\n",
      "f1 = 0.8225806451612903\n",
      "auc = 0.8851827221483312\n",
      "accuracy = 0.9353574926542605\n",
      "time taken =  0:17:35.585132\n"
     ]
    }
   ],
   "source": [
    "current = datetime.now()\n",
    "\n",
    "classifiers = [svc_clf] #the classifier that is to be tested\n",
    "models = ['svm'] #a lebale used to identify the results\n",
    "\n",
    "train_files = ['features/df_tweet_train.pickle'] #the location of the training data\n",
    "\n",
    "eval_files = ['features/df_tweet_eval.pickle'] #the location of the evaluation data\n",
    "\n",
    "for classifier, model in zip(classifiers, models): #zip through the classifier and label combos\n",
    "    for train_file, eval_file in zip(train_files, eval_files): #zip through the train and evaluation data combos\n",
    "        #execute the search_grid() function\n",
    "        best_parameters, conf_matrix, precision, recall, f1, auc_score, accuracy, class_eval = search_grid(classifier,model, train_file, eval_file)\n",
    "        \n",
    "        #append the latest results to the vectors\n",
    "        tf = np.append(tf,train_file)\n",
    "        name = np.append(name,model)\n",
    "        b = ';'.join('{} {}'.format(key, val) for key, val in best_parameters.items())\n",
    "        bp = np.append(bp,b)\n",
    "        tn = np.append(tn,conf_matrix[0][0])\n",
    "        fp = np.append(fp,conf_matrix[0][1])\n",
    "        fn = np.append(fn,conf_matrix[1][0])\n",
    "        tp = np.append(tp,conf_matrix[1][1])\n",
    "        p = np.append(p,precision)\n",
    "        r = np.append(r,recall)\n",
    "        f_1 = np.append(f_1,f1)\n",
    "        auc_sc = np.append(auc_sc,auc_score)\n",
    "        acc = np.append(acc,accuracy)\n",
    "        \n",
    "        class_eval['model'] = model\n",
    "        class_eval['file'] = eval_file\n",
    "\n",
    "        df = df.append(class_eval) #merge the latest predictions for each tweet using this classifier\n",
    "\n",
    "\n",
    "print('time taken = ',datetime.now() - current) #print the time taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[820  11]\n",
      " [ 38 152]]\n",
      "precision = 0.9325153374233128\n",
      "recall = 0.8\n",
      "f1 = 0.8611898016997167\n",
      "auc = 0.89338146811071\n",
      "accuracy = 0.9520078354554359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "log_clf = LogisticRegression(penalty='l2',C=1, random_state=42) #logistic regression with best hyperparameters\n",
    "svc_clf = SVC(C=0.05, kernel='linear', probability = True, random_state=42) #svm with best hyperparameters\n",
    "rf_clf = DecisionTreeClassifier(criterion='gini', random_state=42) #random forest with best hyperparameters\n",
    "dt_clf = RandomForestClassifier(criterion='gini', random_state=42) #random forest with best hyperparameters\n",
    "\n",
    "#create the ensemble\n",
    "e_clf = VotingClassifier(estimators=[('lr', log_clf), ('svm', svc_clf), ('rf', rf_clf), ('dt', dt_clf)],\n",
    "                         voting='soft', weights=[1, 1, 1, 1])\n",
    "\n",
    "#get training and evaluation data\n",
    "x_train, y_train, class_train = xysplit('features/df_tweet_train.pickle') #split training data into X, Y\n",
    "x_eval, y_eval, class_eval = xysplit('features/df_tweet_eval.pickle') #split evaluation data into X, Y\n",
    "\n",
    "e_clf = e_clf.fit(x_train, y_train) #fit the ensemble\n",
    "\n",
    "e_clf_pred = e_clf.predict(x_eval) #predict using evaluation data with best parameters\n",
    "conf_matrix = confusion_matrix(y_eval,e_clf_pred) #build confusion matrix\n",
    "precision = precision_score(y_eval,e_clf_pred) #calculate precision\n",
    "recall = recall_score(y_eval,e_clf_pred) #calculate recall\n",
    "f1 = f1_score(y_eval,e_clf_pred) #calculate f1\n",
    "fpr, tpr, thresholds = roc_curve(y_eval,e_clf_pred)\n",
    "auc_score = auc(fpr, tpr) #calculate auc\n",
    "accuracy = accuracy_score(y_eval,e_clf_pred) #calculate accuracy\n",
    "class_eval['pred'] = e_clf_pred\n",
    "class_eval = class_eval.drop('class_column', axis=1) #join predictions onto actuals\n",
    "print(conf_matrix)\n",
    "print('precision = ' + str(precision))\n",
    "print('recall = ' + str(recall))\n",
    "print('f1 = ' + str(f1))\n",
    "print('auc = ' + str(auc_score))\n",
    "print('accuracy = ' + str(accuracy))\n",
    "\n",
    "#append the latest results to the vectors\n",
    "tf = np.append(tf,'features/df_tweet_train.pickle')\n",
    "name = np.append(name,'ensemble')\n",
    "bp = np.append(bp,'ensemble')\n",
    "tn = np.append(tn,conf_matrix[0][0])\n",
    "fp = np.append(fp,conf_matrix[0][1])\n",
    "fn = np.append(fn,conf_matrix[1][0])\n",
    "tp = np.append(tp,conf_matrix[1][1])\n",
    "p = np.append(p,precision)\n",
    "r = np.append(r,recall)\n",
    "f_1 = np.append(f_1,f1)\n",
    "auc_sc = np.append(auc_sc,auc_score)\n",
    "acc = np.append(acc,accuracy)\n",
    "\n",
    "class_eval['model'] = 'ensemble'\n",
    "class_eval['file'] = 'features/df_tweet_eval.pickle'\n",
    "\n",
    "df = df.append(class_eval) #merge the latest predictions for each tweet using this classifier\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('results/classifier_results.pickle') #pickle the results of actual vs predicted for each tweet\n",
    "\n",
    "classifications = pd.DataFrame({'tf':tf, #create a dataframe to hold the metrics\n",
    "                                'name':name,\n",
    "                               'bp':bp,\n",
    "                               'tn':tn,\n",
    "                               'fp':fp,\n",
    "                               'fn':fn,\n",
    "                               'tp':tp,\n",
    "                               'p':p,\n",
    "                               'r':r,\n",
    "                               'f_1':f_1,\n",
    "                               'auc_sc':auc_sc,\n",
    "                               'acc':acc})\n",
    "classifications.to_pickle('results/classifications.pickle') #pickle the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print metric results descending by f1 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>auc_sc</th>\n",
       "      <th>bp</th>\n",
       "      <th>f_1</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>name</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>tf</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.952008</td>\n",
       "      <td>0.893381</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>0.861190</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>0.932515</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>features/df_tweet_train.pickle</td>\n",
       "      <td>820.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950049</td>\n",
       "      <td>0.900298</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>features/df_tweet_tf_train.pickle</td>\n",
       "      <td>814.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950049</td>\n",
       "      <td>0.900298</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>features/df_tweet_tfidf_train.pickle</td>\n",
       "      <td>814.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.947111</td>\n",
       "      <td>0.912702</td>\n",
       "      <td>C 1;penalty l2;random_state 42</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>features/df_tweet_train.pickle</td>\n",
       "      <td>804.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941234</td>\n",
       "      <td>0.896912</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.826316</td>\n",
       "      <td>features/df_tweetbio_tfidf_train.pickle</td>\n",
       "      <td>804.0</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941234</td>\n",
       "      <td>0.896912</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.826316</td>\n",
       "      <td>features/df_tweetbio_tf_train.pickle</td>\n",
       "      <td>804.0</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.939275</td>\n",
       "      <td>0.889619</td>\n",
       "      <td>C 0.5;penalty l2;random_state 42</td>\n",
       "      <td>0.832432</td>\n",
       "      <td>36.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>features/df_tweet_train_nc.pickle</td>\n",
       "      <td>805.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.936337</td>\n",
       "      <td>0.889844</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>features/df_tweetbio_tfidf_train_nc.pickle</td>\n",
       "      <td>801.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.936337</td>\n",
       "      <td>0.889844</td>\n",
       "      <td>C 0.05;penalty l2;random_state 42</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>features/df_tweetbio_tf_train_nc.pickle</td>\n",
       "      <td>801.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.933399</td>\n",
       "      <td>0.896159</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.823834</td>\n",
       "      <td>31.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.811224</td>\n",
       "      <td>0.836842</td>\n",
       "      <td>features/df_tweet_train.pickle</td>\n",
       "      <td>794.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.935357</td>\n",
       "      <td>0.885183</td>\n",
       "      <td>C 0.05;kernel linear;random_state 42</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.840659</td>\n",
       "      <td>0.805263</td>\n",
       "      <td>features/df_tweet_train.pickle</td>\n",
       "      <td>802.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.935357</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>C 0.5;penalty l2;random_state 42</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>40.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>features/df_tweet_tfidf_train_nc.pickle</td>\n",
       "      <td>805.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.935357</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>C 0.5;penalty l2;random_state 42</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>40.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>features/df_tweet_tf_train_nc.pickle</td>\n",
       "      <td>805.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.932419</td>\n",
       "      <td>0.887437</td>\n",
       "      <td>C 0.1;penalty l2;random_state 42</td>\n",
       "      <td>0.817942</td>\n",
       "      <td>35.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.820106</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>features/df_tweetbio_train.pickle</td>\n",
       "      <td>797.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.922625</td>\n",
       "      <td>0.871271</td>\n",
       "      <td>C 0.5;penalty l2;random_state 42</td>\n",
       "      <td>0.791557</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>features/df_tweetbio_train_nc.pickle</td>\n",
       "      <td>792.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.924584</td>\n",
       "      <td>0.803458</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.750809</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.974790</td>\n",
       "      <td>0.610526</td>\n",
       "      <td>features/df_tweet_tf_train.pickle</td>\n",
       "      <td>828.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.924584</td>\n",
       "      <td>0.803458</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.750809</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.974790</td>\n",
       "      <td>0.610526</td>\n",
       "      <td>features/df_tweet_tfidf_train.pickle</td>\n",
       "      <td>828.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.922625</td>\n",
       "      <td>0.804285</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.747604</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.615789</td>\n",
       "      <td>features/df_tweet_train.pickle</td>\n",
       "      <td>825.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.907933</td>\n",
       "      <td>0.829768</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.740331</td>\n",
       "      <td>56.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>features/df_tweet_tfidf_train_nc.pickle</td>\n",
       "      <td>793.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.907933</td>\n",
       "      <td>0.829768</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.740331</td>\n",
       "      <td>56.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>features/df_tweet_tf_train_nc.pickle</td>\n",
       "      <td>793.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.903036</td>\n",
       "      <td>0.838939</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>0.738786</td>\n",
       "      <td>50.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>features/df_tweet_train_nc.pickle</td>\n",
       "      <td>782.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.904016</td>\n",
       "      <td>0.835480</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>0.737968</td>\n",
       "      <td>52.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>features/df_tweet_tf_train.pickle</td>\n",
       "      <td>785.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.904016</td>\n",
       "      <td>0.835480</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>0.737968</td>\n",
       "      <td>52.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>features/df_tweet_tfidf_train.pickle</td>\n",
       "      <td>785.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.920666</td>\n",
       "      <td>0.792932</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.734426</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>features/df_tweet_train_nc.pickle</td>\n",
       "      <td>828.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.918707</td>\n",
       "      <td>0.791728</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.729642</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>features/df_tweet_tfidf_train_nc.pickle</td>\n",
       "      <td>826.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.918707</td>\n",
       "      <td>0.791728</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.729642</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>features/df_tweet_tf_train_nc.pickle</td>\n",
       "      <td>826.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.897160</td>\n",
       "      <td>0.829239</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.722955</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.724868</td>\n",
       "      <td>0.721053</td>\n",
       "      <td>features/df_tweetbio_tf_train.pickle</td>\n",
       "      <td>779.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.897160</td>\n",
       "      <td>0.829239</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.722955</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.724868</td>\n",
       "      <td>0.721053</td>\n",
       "      <td>features/df_tweetbio_tfidf_train.pickle</td>\n",
       "      <td>779.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.890304</td>\n",
       "      <td>0.814877</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>58.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.694737</td>\n",
       "      <td>features/df_tweetbio_train_nc.pickle</td>\n",
       "      <td>777.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.882468</td>\n",
       "      <td>0.785705</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>features/df_tweetbio_tfidf_train_nc.pickle</td>\n",
       "      <td>781.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.882468</td>\n",
       "      <td>0.785705</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>70.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>features/df_tweetbio_tf_train_nc.pickle</td>\n",
       "      <td>781.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.901077</td>\n",
       "      <td>0.744360</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>features/df_tweetbio_tf_train.pickle</td>\n",
       "      <td>826.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.901077</td>\n",
       "      <td>0.744360</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>features/df_tweetbio_tfidf_train.pickle</td>\n",
       "      <td>826.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.855044</td>\n",
       "      <td>0.801336</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>54.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.591304</td>\n",
       "      <td>0.715789</td>\n",
       "      <td>features/df_tweetbio_train.pickle</td>\n",
       "      <td>737.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.887365</td>\n",
       "      <td>0.752176</td>\n",
       "      <td>C 0.5;penalty l1;random_state 42</td>\n",
       "      <td>0.639498</td>\n",
       "      <td>88.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>features/df_tweet_count_features_train.pickle</td>\n",
       "      <td>804.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.893242</td>\n",
       "      <td>0.723307</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>0.612100</td>\n",
       "      <td>104.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>features/df_tweetbio_train.pickle</td>\n",
       "      <td>826.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.887365</td>\n",
       "      <td>0.713608</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.590747</td>\n",
       "      <td>107.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.436842</td>\n",
       "      <td>features/df_tweetbio_tfidf_train_nc.pickle</td>\n",
       "      <td>823.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.887365</td>\n",
       "      <td>0.713608</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.590747</td>\n",
       "      <td>107.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.436842</td>\n",
       "      <td>features/df_tweetbio_tf_train_nc.pickle</td>\n",
       "      <td>823.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.876592</td>\n",
       "      <td>0.682630</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>119.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>features/df_tweetbio_train_nc.pickle</td>\n",
       "      <td>824.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.851126</td>\n",
       "      <td>0.660897</td>\n",
       "      <td>criterion gini;random_state 42</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>122.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>features/df_tweet_count_features_train.pickle</td>\n",
       "      <td>801.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.768854</td>\n",
       "      <td>0.675312</td>\n",
       "      <td>criterion entropy;random_state 42</td>\n",
       "      <td>0.458716</td>\n",
       "      <td>90.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>dt</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>features/df_tweet_count_features_train.pickle</td>\n",
       "      <td>685.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc    auc_sc                                    bp       f_1     fn  \\\n",
       "40  0.952008  0.893381                              ensemble  0.861190   38.0   \n",
       "1   0.950049  0.900298     C 0.05;penalty l2;random_state 42  0.859504   34.0   \n",
       "0   0.950049  0.900298     C 0.05;penalty l2;random_state 42  0.859504   34.0   \n",
       "2   0.947111  0.912702        C 1;penalty l2;random_state 42  0.857895   27.0   \n",
       "3   0.941234  0.896912     C 0.05;penalty l2;random_state 42  0.839572   33.0   \n",
       "4   0.941234  0.896912     C 0.05;penalty l2;random_state 42  0.839572   33.0   \n",
       "8   0.939275  0.889619      C 0.5;penalty l2;random_state 42  0.832432   36.0   \n",
       "9   0.936337  0.889844     C 0.05;penalty l2;random_state 42  0.826667   35.0   \n",
       "10  0.936337  0.889844     C 0.05;penalty l2;random_state 42  0.826667   35.0   \n",
       "15  0.933399  0.896159        criterion gini;random_state 42  0.823834   31.0   \n",
       "39  0.935357  0.885183  C 0.05;kernel linear;random_state 42  0.822581   37.0   \n",
       "6   0.935357  0.879093      C 0.5;penalty l2;random_state 42  0.819672   40.0   \n",
       "7   0.935357  0.879093      C 0.5;penalty l2;random_state 42  0.819672   40.0   \n",
       "5   0.932419  0.887437      C 0.1;penalty l2;random_state 42  0.817942   35.0   \n",
       "11  0.922625  0.871271      C 0.5;penalty l2;random_state 42  0.791557   40.0   \n",
       "27  0.924584  0.803458        criterion gini;random_state 42  0.750809   74.0   \n",
       "26  0.924584  0.803458        criterion gini;random_state 42  0.750809   74.0   \n",
       "28  0.922625  0.804285        criterion gini;random_state 42  0.747604   73.0   \n",
       "19  0.907933  0.829768        criterion gini;random_state 42  0.740331   56.0   \n",
       "20  0.907933  0.829768        criterion gini;random_state 42  0.740331   56.0   \n",
       "21  0.903036  0.838939     criterion entropy;random_state 42  0.738786   50.0   \n",
       "14  0.904016  0.835480     criterion entropy;random_state 42  0.737968   52.0   \n",
       "13  0.904016  0.835480     criterion entropy;random_state 42  0.737968   52.0   \n",
       "34  0.920666  0.792932        criterion gini;random_state 42  0.734426   78.0   \n",
       "32  0.918707  0.791728        criterion gini;random_state 42  0.729642   78.0   \n",
       "33  0.918707  0.791728        criterion gini;random_state 42  0.729642   78.0   \n",
       "17  0.897160  0.829239        criterion gini;random_state 42  0.722955   53.0   \n",
       "16  0.897160  0.829239        criterion gini;random_state 42  0.722955   53.0   \n",
       "24  0.890304  0.814877     criterion entropy;random_state 42  0.702128   58.0   \n",
       "22  0.882468  0.785705        criterion gini;random_state 42  0.666667   70.0   \n",
       "23  0.882468  0.785705        criterion gini;random_state 42  0.666667   70.0   \n",
       "30  0.901077  0.744360        criterion gini;random_state 42  0.650519   96.0   \n",
       "29  0.901077  0.744360        criterion gini;random_state 42  0.650519   96.0   \n",
       "18  0.855044  0.801336        criterion gini;random_state 42  0.647619   54.0   \n",
       "12  0.887365  0.752176      C 0.5;penalty l1;random_state 42  0.639498   88.0   \n",
       "31  0.893242  0.723307     criterion entropy;random_state 42  0.612100  104.0   \n",
       "35  0.887365  0.713608        criterion gini;random_state 42  0.590747  107.0   \n",
       "36  0.887365  0.713608        criterion gini;random_state 42  0.590747  107.0   \n",
       "37  0.876592  0.682630     criterion entropy;random_state 42  0.529851  119.0   \n",
       "38  0.851126  0.660897        criterion gini;random_state 42  0.472222  122.0   \n",
       "25  0.768854  0.675312     criterion entropy;random_state 42  0.458716   90.0   \n",
       "\n",
       "       fp      name         p         r  \\\n",
       "40   11.0  ensemble  0.932515  0.800000   \n",
       "1    17.0        lr  0.901734  0.821053   \n",
       "0    17.0        lr  0.901734  0.821053   \n",
       "2    27.0        lr  0.857895  0.857895   \n",
       "3    27.0        lr  0.853261  0.826316   \n",
       "4    27.0        lr  0.853261  0.826316   \n",
       "8    26.0        lr  0.855556  0.810526   \n",
       "9    30.0        lr  0.837838  0.815789   \n",
       "10   30.0        lr  0.837838  0.815789   \n",
       "15   37.0        dt  0.811224  0.836842   \n",
       "39   29.0       svm  0.840659  0.805263   \n",
       "6    26.0        lr  0.852273  0.789474   \n",
       "7    26.0        lr  0.852273  0.789474   \n",
       "5    34.0        lr  0.820106  0.815789   \n",
       "11   39.0        lr  0.793651  0.789474   \n",
       "27    3.0        rf  0.974790  0.610526   \n",
       "26    3.0        rf  0.974790  0.610526   \n",
       "28    6.0        rf  0.951220  0.615789   \n",
       "19   38.0        dt  0.779070  0.705263   \n",
       "20   38.0        dt  0.779070  0.705263   \n",
       "21   49.0        dt  0.740741  0.736842   \n",
       "14   46.0        dt  0.750000  0.726316   \n",
       "13   46.0        dt  0.750000  0.726316   \n",
       "34    3.0        rf  0.973913  0.589474   \n",
       "32    5.0        rf  0.957265  0.589474   \n",
       "33    5.0        rf  0.957265  0.589474   \n",
       "17   52.0        dt  0.724868  0.721053   \n",
       "16   52.0        dt  0.724868  0.721053   \n",
       "24   54.0        dt  0.709677  0.694737   \n",
       "22   50.0        dt  0.705882  0.631579   \n",
       "23   50.0        dt  0.705882  0.631579   \n",
       "30    5.0        rf  0.949495  0.494737   \n",
       "29    5.0        rf  0.949495  0.494737   \n",
       "18   94.0        dt  0.591304  0.715789   \n",
       "12   27.0        lr  0.790698  0.536842   \n",
       "31    5.0        rf  0.945055  0.452632   \n",
       "35    8.0        rf  0.912088  0.436842   \n",
       "36    8.0        rf  0.912088  0.436842   \n",
       "37    7.0        rf  0.910256  0.373684   \n",
       "38   30.0        rf  0.693878  0.357895   \n",
       "25  146.0        dt  0.406504  0.526316   \n",
       "\n",
       "                                               tf     tn     tp  \n",
       "40                 features/df_tweet_train.pickle  820.0  152.0  \n",
       "1               features/df_tweet_tf_train.pickle  814.0  156.0  \n",
       "0            features/df_tweet_tfidf_train.pickle  814.0  156.0  \n",
       "2                  features/df_tweet_train.pickle  804.0  163.0  \n",
       "3         features/df_tweetbio_tfidf_train.pickle  804.0  157.0  \n",
       "4            features/df_tweetbio_tf_train.pickle  804.0  157.0  \n",
       "8               features/df_tweet_train_nc.pickle  805.0  154.0  \n",
       "9      features/df_tweetbio_tfidf_train_nc.pickle  801.0  155.0  \n",
       "10        features/df_tweetbio_tf_train_nc.pickle  801.0  155.0  \n",
       "15                 features/df_tweet_train.pickle  794.0  159.0  \n",
       "39                 features/df_tweet_train.pickle  802.0  153.0  \n",
       "6         features/df_tweet_tfidf_train_nc.pickle  805.0  150.0  \n",
       "7            features/df_tweet_tf_train_nc.pickle  805.0  150.0  \n",
       "5               features/df_tweetbio_train.pickle  797.0  155.0  \n",
       "11           features/df_tweetbio_train_nc.pickle  792.0  150.0  \n",
       "27              features/df_tweet_tf_train.pickle  828.0  116.0  \n",
       "26           features/df_tweet_tfidf_train.pickle  828.0  116.0  \n",
       "28                 features/df_tweet_train.pickle  825.0  117.0  \n",
       "19        features/df_tweet_tfidf_train_nc.pickle  793.0  134.0  \n",
       "20           features/df_tweet_tf_train_nc.pickle  793.0  134.0  \n",
       "21              features/df_tweet_train_nc.pickle  782.0  140.0  \n",
       "14              features/df_tweet_tf_train.pickle  785.0  138.0  \n",
       "13           features/df_tweet_tfidf_train.pickle  785.0  138.0  \n",
       "34              features/df_tweet_train_nc.pickle  828.0  112.0  \n",
       "32        features/df_tweet_tfidf_train_nc.pickle  826.0  112.0  \n",
       "33           features/df_tweet_tf_train_nc.pickle  826.0  112.0  \n",
       "17           features/df_tweetbio_tf_train.pickle  779.0  137.0  \n",
       "16        features/df_tweetbio_tfidf_train.pickle  779.0  137.0  \n",
       "24           features/df_tweetbio_train_nc.pickle  777.0  132.0  \n",
       "22     features/df_tweetbio_tfidf_train_nc.pickle  781.0  120.0  \n",
       "23        features/df_tweetbio_tf_train_nc.pickle  781.0  120.0  \n",
       "30           features/df_tweetbio_tf_train.pickle  826.0   94.0  \n",
       "29        features/df_tweetbio_tfidf_train.pickle  826.0   94.0  \n",
       "18              features/df_tweetbio_train.pickle  737.0  136.0  \n",
       "12  features/df_tweet_count_features_train.pickle  804.0  102.0  \n",
       "31              features/df_tweetbio_train.pickle  826.0   86.0  \n",
       "35     features/df_tweetbio_tfidf_train_nc.pickle  823.0   83.0  \n",
       "36        features/df_tweetbio_tf_train_nc.pickle  823.0   83.0  \n",
       "37           features/df_tweetbio_train_nc.pickle  824.0   71.0  \n",
       "38  features/df_tweet_count_features_train.pickle  801.0   68.0  \n",
       "25  features/df_tweet_count_features_train.pickle  685.0  100.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications.sort_values(by='f_1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
